{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import lightgbm as lgb"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "LHWjGnlgyeFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    \"\"\"Loads the training and test datasets.\"\"\"\n",
        "    try:\n",
        "        train_df = pd.read_csv(\"train.csv\")\n",
        "        test1_df = pd.read_csv(\"test_1.csv\")\n",
        "        test2_df = pd.read_csv(\"test_2.csv\")\n",
        "        print(\"Data loaded successfully.\")\n",
        "        print(f\"Train shape: {train_df.shape}\")\n",
        "        print(f\"Test1 shape: {test1_df.shape}\")\n",
        "        print(f\"Test2 shape: {test2_df.shape}\")\n",
        "        return train_df, test1_df, test2_df\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error loading data: {e}. Please ensure train.csv, test_1.csv, and test_2.csv are in the same directory.\")\n",
        "        return None, None, None\n",
        "\n"
      ],
      "metadata": {
        "id": "7Hw_zslgyoG-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_feature_columns(df):\n",
        "    \"\"\"Identifies molecular, ECFP, and FCFP feature columns.\"\"\"\n",
        "    molecular_features = []\n",
        "    ecfp_features = []\n",
        "    fcfp_features = []\n",
        "\n",
        "    # Assuming molecular features are between 'BalabanJ' and 'qed'\n",
        "    # Find first and last standard molecular feature to get the range\n",
        "    # These are example column names, adjust if the actual names differ slightly\n",
        "    # or if they are not contiguous.\n",
        "    std_mol_feature_start_example = 'BalabanJ'\n",
        "    std_mol_feature_end_example = 'qed'\n",
        "\n",
        "    if std_mol_feature_start_example in df.columns and std_mol_feature_end_example in df.columns:\n",
        "        start_idx = df.columns.get_loc(std_mol_feature_start_example)\n",
        "        end_idx = df.columns.get_loc(std_mol_feature_end_example)\n",
        "        if start_idx <= end_idx:\n",
        "            molecular_features = df.columns[start_idx : end_idx+1].tolist()\n",
        "        else:\n",
        "            print(f\"Warning: Molecular feature end '{std_mol_feature_end_example}' found before start '{std_mol_feature_start_example}'.\")\n",
        "    else:\n",
        "        print(f\"Warning: Could not find '{std_mol_feature_start_example}' or '{std_mol_feature_end_example}' in columns.\")\n",
        "        # Fallback: try to infer based on known number of features if specific names fail\n",
        "        # This is a heuristic and might not be robust if column order changes\n",
        "        if len(df.columns) > 200 and not any(c.startswith('ecfc_') or c.startswith('fcfc_') for c in df.columns[1:200]):\n",
        "             # Assuming 'smiles' is the first column, then 199 molecular features\n",
        "            potential_mol_cols = [col for col in df.columns if not col.startswith('ecfc_') and not col.startswith('fcfc_') and col not in ['smiles', 'class', 'series']]\n",
        "            if len(potential_mol_cols) == 199: # As per readme\n",
        "                 molecular_features = potential_mol_cols\n",
        "            else: # If still not found, try to locate them by excluding others\n",
        "                all_cols = set(df.columns)\n",
        "                fingerprint_cols = {col for col in all_cols if col.startswith('ecfc_') or col.startswith('fcfc_')}\n",
        "                id_cols = {'smiles', 'class', 'series'} # 'class' and 'series' might not be in all DFs\n",
        "                potential_mol_cols = list(all_cols - fingerprint_cols - id_cols)\n",
        "                # This is very heuristic, assuming they are grouped and non-fingerprint\n",
        "                # A more robust way would be to have an explicit list of these 199 features\n",
        "                # For now, we'll rely on the start/end columns or the count.\n",
        "                # If the above specific start/end are not found, this part is tricky.\n",
        "                # Let's assume the problem setter ensures these columns are present and named as in readme.\n",
        "                # The readme says: \"199 molecular features computed with the rdkit package (from column BalabanJ to qed)\"\n",
        "                # So the primary method using get_loc should work if columns are named exactly.\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col.startswith(\"ecfc_\"):\n",
        "            ecfp_features.append(col)\n",
        "        elif col.startswith(\"fcfc_\"):\n",
        "            fcfp_features.append(col)\n",
        "\n",
        "    if not molecular_features:\n",
        "        print(\"Critical Warning: Molecular features could not be identified robustly. Predictions may be unreliable.\")\n",
        "        # Fallback: take all columns that are not smiles, class, series, ecfc, fcfc\n",
        "        # This is a last resort.\n",
        "        non_feature_cols = ['smiles', 'class', 'series']\n",
        "        molecular_features = [col for col in df.columns if col not in non_feature_cols and not col.startswith('ecfc_') and not col.startswith('fcfc_')]\n",
        "        print(f\"Fallback: Identified {len(molecular_features)} potential molecular features.\")\n",
        "\n",
        "\n",
        "    print(f\"Identified {len(molecular_features)} molecular features.\")\n",
        "    print(f\"Identified {len(ecfp_features)} ECFP features.\")\n",
        "    print(f\"Identified {len(fcfp_features)} FCFP features.\")\n",
        "\n",
        "    all_features = molecular_features + ecfp_features + fcfp_features\n",
        "    return molecular_features, ecfp_features, fcfp_features, all_features"
      ],
      "metadata": {
        "id": "4VrxWNKzyoTr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(train_df, test1_df, test2_df, molecular_features, all_features):\n",
        "    \"\"\"Preprocesses the data: scales molecular features and prepares X, y.\"\"\"\n",
        "\n",
        "    X_train_full = train_df[all_features].copy()\n",
        "    y_train_full = train_df['class'].copy()\n",
        "\n",
        "    X_test1 = test1_df[all_features].copy()\n",
        "    X_test2 = test2_df[all_features].copy()\n",
        "\n",
        "    # Scale molecular features\n",
        "    # Ensure molecular_features only contains numeric columns before scaling\n",
        "    numeric_molecular_features = X_train_full[molecular_features].select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "    if not numeric_molecular_features:\n",
        "        print(\"Warning: No numeric molecular features found to scale.\")\n",
        "    else:\n",
        "        scaler = StandardScaler()\n",
        "        X_train_full[numeric_molecular_features] = scaler.fit_transform(X_train_full[numeric_molecular_features])\n",
        "        X_test1[numeric_molecular_features] = scaler.transform(X_test1[numeric_molecular_features])\n",
        "        X_test2[numeric_molecular_features] = scaler.transform(X_test2[numeric_molecular_features])\n",
        "        print(\"Molecular features scaled.\")\n",
        "\n",
        "    return X_train_full, y_train_full, X_test1, X_test2"
      ],
      "metadata": {
        "id": "tvZXR9WZyofm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train):\n",
        "    \"\"\"Trains a LightGBM model.\"\"\"\n",
        "    # Calculate scale_pos_weight for imbalanced classes\n",
        "    class_counts = y_train.value_counts()\n",
        "    scale_pos_weight = class_counts[0] / class_counts[1] if 1 in class_counts and class_counts[1] > 0 else 1\n",
        "\n",
        "    model = lgb.LGBMClassifier(\n",
        "        objective='binary',\n",
        "        metric='binary_logloss', # Common metric for binary classification\n",
        "        n_estimators=1000,      # Can be tuned\n",
        "        learning_rate=0.05,     # Can be tuned\n",
        "        num_leaves=31,          # Can be tuned\n",
        "        max_depth=-1,           # No limit\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        scale_pos_weight=scale_pos_weight, # Address class imbalance\n",
        "        # colsample_bytree=0.8, # Feature fraction\n",
        "        # subsample=0.8,        # Bagging fraction\n",
        "        # reg_alpha=0.1,        # L1 regularization\n",
        "        # reg_lambda=0.1        # L2 regularization\n",
        "    )\n",
        "\n",
        "    # Using early stopping for optimal number of estimators\n",
        "    # For this, we need a validation set. If not doing CV here,\n",
        "    # we can train on full data for a fixed number of estimators.\n",
        "    # For simplicity in this script, we'll train on full X_train without early stopping here.\n",
        "    # Proper hyperparameter tuning would involve CV.\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Model trained successfully.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "BY8Q4k43yomk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_df, test1_df, test2_df = load_data()\n",
        "    if train_df is None:\n",
        "        return\n",
        "\n",
        "    molecular_features, ecfp_features, fcfp_features, all_features = identify_feature_columns(train_df)\n",
        "\n",
        "    if not all_features:\n",
        "        print(\"Critical error: No features identified. Exiting.\")\n",
        "        return\n",
        "\n",
        "    X_train_full, y_train_full, X_test1, X_test2 = preprocess_data(\n",
        "        train_df.copy(), test1_df.copy(), test2_df.copy(), molecular_features, all_features\n",
        "    )\n",
        "\n",
        "    # --- Train final model on all training data ---\n",
        "    print(\"\\n--- Training Final Model on Full Training Data ---\")\n",
        "    final_model = train_model(X_train_full, y_train_full)\n",
        "\n",
        "    # --- Task 1: Predict toxicity on test set 1 ---\n",
        "    print(\"\\n--- Task 1: Predictions for test_1.csv ---\")\n",
        "    task1_predictions = final_model.predict(X_test1)\n",
        "    task1_pred_proba = final_model.predict_proba(X_test1)[:, 1] # Probabilities for class 1\n",
        "\n",
        "    # Store predictions for submission\n",
        "    test1_df['predicted_class_task1'] = task1_predictions\n",
        "    # test1_df[['smiles', 'predicted_class_task1']].to_csv(\"task1_predictions.csv\", index=False)\n",
        "    print(\"Predictions for test_1.csv generated.\")\n",
        "    print(f\"Example predictions for test_1.csv: {task1_predictions[:10]}\")\n",
        "\n",
        "\n",
        "    # --- Task 1: Evaluation Metric Demonstration (Cohen Kappa) ---\n",
        "    print(\"\\n--- Task 1: Cohen Kappa Score (Demonstration) ---\")\n",
        "    # To demonstrate metric calculation, split train_df into a demo train/val set\n",
        "    X_temp_train, X_temp_val, y_temp_train, y_temp_val = train_test_split(\n",
        "        X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
        "    )\n",
        "\n",
        "    print(\"Training a temporary model for demonstration purposes...\")\n",
        "    demo_model_task1 = train_model(X_temp_train, y_temp_train)\n",
        "    demo_preds_task1 = demo_model_task1.predict(X_temp_val)\n",
        "    kappa_demo = cohen_kappa_score(y_temp_val, demo_preds_task1)\n",
        "    print(f\"Demonstration Cohen Kappa Score on internal validation set: {kappa_demo:.4f}\")\n",
        "    print(\"Note: This Kappa score is on an internal split of the training data for demonstration.\")\n",
        "    print(\"The actual Task 1 Cohen Kappa would be calculated using the predictions on test_1.csv and its true (hidden) labels.\")\n",
        "\n",
        "    # --- Task 2: Predict toxicity on test set 2 ---\n",
        "    print(\"\\n--- Task 2: Predictions for test_2.csv ---\")\n",
        "    task2_predictions = final_model.predict(X_test2)\n",
        "\n",
        "    # Store predictions for submission, including series\n",
        "    test2_df['predicted_class_task2'] = task2_predictions\n",
        "    # test2_df[['smiles', 'series', 'predicted_class_task2']].to_csv(\"task2_predictions.csv\", index=False)\n",
        "    print(\"Predictions for test_2.csv generated.\")\n",
        "\n",
        "    # Group predictions by series\n",
        "    task2_results_df = test2_df[['smiles', 'series', 'predicted_class_task2']].copy()\n",
        "    print(\"\\nExample predictions for test_2.csv grouped by series:\")\n",
        "    for series_id, group in task2_results_df.groupby('series'):\n",
        "        print(f\"\\nSeries {series_id}:\")\n",
        "        print(group.head())\n",
        "        # print(f\"  Number of molecules: {len(group)}\")\n",
        "        # print(f\"  Predicted toxic: {group['predicted_class_task2'].sum()} / {len(group)}\")\n",
        "\n",
        "    print(\"\\n--- Task 2: Evaluation Metric (Average Accuracy by Series) ---\")\n",
        "    print(\"To calculate the actual Task 2 metric (average accuracy across 6 series):\")\n",
        "    print(\"1. Obtain the true labels for test_2.csv.\")\n",
        "    print(\"2. For each of the 6 molecular series:\")\n",
        "    print(\"   a. Filter predictions and true labels for that series.\")\n",
        "    print(\"   b. Calculate accuracy_score(true_labels_series, predicted_labels_series).\")\n",
        "    print(\"3. Average these 6 accuracy scores.\")\n",
        "    print(\"Demonstration of grouping (actual calculation requires true labels for test_2.csv):\")\n",
        "\n",
        "    # Example of how one might calculate if true labels were available for test_2_df\n",
        "    # Assume test2_df had a 'true_class' column for demonstration\n",
        "    # test2_df['true_class_placeholder'] = np.random.randint(0,2,size=len(test2_df)) # Placeholder\n",
        "    # accuracies_per_series_demo = []\n",
        "    # if 'true_class_placeholder' in test2_df.columns:\n",
        "    #     for series_id, group in test2_df.groupby('series'):\n",
        "    #         acc = accuracy_score(group['true_class_placeholder'], group['predicted_class_task2'])\n",
        "    #         accuracies_per_series_demo.append(acc)\n",
        "    #         print(f\"  Demo Accuracy for Series {series_id}: {acc:.4f} (using placeholder true labels)\")\n",
        "    #     if accuracies_per_series_demo:\n",
        "    #         print(f\"  Demo Average Accuracy: {np.mean(accuracies_per_series_demo):.4f}\")\n",
        "    # else:\n",
        "    #     print(\"  (Skipping demo accuracy calculation as placeholder true labels are not set up for test_2.csv)\")\n",
        "\n",
        "\n",
        "    # --- Task 3: Select 200 most reliable predictions from test set 1 ---\n",
        "    print(\"\\n--- Task 3: Identify 200 Most Reliable Predictions from test_1.csv ---\")\n",
        "    # Using task1_pred_proba from the final_model on X_test1\n",
        "    confidence = np.abs(task1_pred_proba - 0.5) # Higher value means more confident (further from 0.5)\n",
        "\n",
        "    test1_predictions_df = pd.DataFrame({\n",
        "        'smiles': test1_df['smiles'], # Assuming test1_df still has original index\n",
        "        'predicted_class': task1_predictions,\n",
        "        'probability_class1': task1_pred_proba,\n",
        "        'confidence': confidence\n",
        "    })\n",
        "\n",
        "    # Sort by confidence and select top 200\n",
        "    top_200_reliable = test1_predictions_df.sort_values(by='confidence', ascending=False).head(200)\n",
        "\n",
        "    # Store these top 200 predictions for submission\n",
        "    # top_200_reliable[['smiles', 'predicted_class']].to_csv(\"task3_top_200_predictions.csv\", index=False)\n",
        "    print(f\"Identified {len(top_200_reliable)} most reliable predictions for test_1.csv.\")\n",
        "    print(\"Top 5 most reliable predictions for test_1.csv:\")\n",
        "    print(top_200_reliable.head())\n",
        "\n",
        "    print(\"\\n--- Task 3: Accuracy on Most Reliable (Demonstration) ---\")\n",
        "    # Use the demo_model_task1 and its predictions on X_temp_val\n",
        "    demo_proba_task3 = demo_model_task1.predict_proba(X_temp_val)[:, 1]\n",
        "    demo_confidence_task3 = np.abs(demo_proba_task3 - 0.5)\n",
        "\n",
        "    # Create a DataFrame for demo validation results\n",
        "    demo_val_results_df = pd.DataFrame({\n",
        "        'true_class': y_temp_val,\n",
        "        'predicted_class': demo_preds_task1, # Predictions from demo_model_task1\n",
        "        'probability_class1': demo_proba_task3,\n",
        "        'confidence': demo_confidence_task3\n",
        "    })\n",
        "\n",
        "    # Determine N for demonstration (proportional to 200/750)\n",
        "    N_demo = int(np.ceil(len(X_temp_val) * (200 / len(X_test1)))) # len(X_test1) is 750\n",
        "\n",
        "    demo_top_N_reliable = demo_val_results_df.sort_values(by='confidence', ascending=False).head(N_demo)\n",
        "\n",
        "    accuracy_top_N_demo = accuracy_score(demo_top_N_reliable['true_class'], demo_top_N_reliable['predicted_class'])\n",
        "    print(f\"Demonstration Accuracy on top {N_demo} most reliable predictions (from internal validation set): {accuracy_top_N_demo:.4f}\")\n",
        "    print(\"Note: This accuracy is on an internal split of the training data for demonstration.\")\n",
        "    print(\"The actual Task 3 Accuracy would be calculated using the top 200 predictions on test_1.csv and its true (hidden) labels.\")\n",
        "\n",
        "    print(\"\\n\\n--- Summary of Files to be Generated for Submission (if uncommented) ---\")\n",
        "    print(\"1. task1_predictions.csv: Contains 'smiles' and 'predicted_class_task1' for all molecules in test_1.csv.\")\n",
        "    print(\"   (The submission file for Task 3 should be the first 200 rows of this file, if sorted by reliability).\")\n",
        "    print(\"   Alternatively, a separate file like task3_top_200_predictions.csv can be made.\")\n",
        "    print(\"2. task2_predictions.csv: Contains 'smiles', 'series', and 'predicted_class_task2' for all molecules in test_2.csv.\")\n",
        "    print(\"\\nTo create the submission file for Task 3 (first 200 rows of test_1.csv, ordered by reliability):\")\n",
        "    print(\"  submission_task3_df = top_200_reliable[['smiles', 'predicted_class']]\")\n",
        "    print(\"  # submission_task3_df.to_csv('submission_task3.csv', index=False)\")\n",
        "    print(\"  The 'task1_predictions.csv' file, if it were to be the base for Task 3, would need to be sorted by reliability first, then the top 200 taken.\")\n",
        "    print(\"  A common approach for Kaggle-like challenges is to submit a single prediction file for test_set_1, and the platform evaluates Task 1 and Task 3 from it.\")\n",
        "    print(\"  For Task 3, it implies the submitted predictions for test_set_1 should be ordered by reliability, most reliable first.\")\n",
        "    print(\"  Let's prepare a test_1_submission_ordered.csv for this purpose:\")\n",
        "\n",
        "    test1_submission_ordered_df = test1_predictions_df.sort_values(by='confidence', ascending=False)[['smiles', 'predicted_class']]\n",
        "    # test1_submission_ordered_df.to_csv(\"test_1_submission_ordered_by_reliability.csv\", index=False, header=False) # Often no header for submission\n",
        "    print(\"  'test_1_submission_ordered_by_reliability.csv' (if uncommented) would be structured for Task 1 and Task 3 evaluation.\")\n",
        "    print(f\"  Shape of ordered test_1 submission: {test1_submission_ordered_df.shape}\")\n"
      ],
      "metadata": {
        "id": "bQG5o-0uzp6C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VZfoZcpzqBw",
        "outputId": "93f341cb-6fc2-4aa7-8944-ffda6e6c90ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Train shape: (9415, 4297)\n",
            "Test1 shape: (750, 4296)\n",
            "Test2 shape: (478, 4297)\n",
            "Identified 199 molecular features.\n",
            "Identified 2048 ECFP features.\n",
            "Identified 2048 FCFP features.\n",
            "Molecular features scaled.\n",
            "\n",
            "--- Training Final Model on Full Training Data ---\n",
            "[LightGBM] [Info] Number of positive: 4816, number of negative: 4599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.414011 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 31564\n",
            "[LightGBM] [Info] Number of data points in the train set: 9415, number of used features: 3530\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.511524 -> initscore=0.046105\n",
            "[LightGBM] [Info] Start training from score 0.046105\n",
            "Model trained successfully.\n",
            "\n",
            "--- Task 1: Predictions for test_1.csv ---\n",
            "Predictions for test_1.csv generated.\n",
            "Example predictions for test_1.csv: [0 0 0 1 1 1 1 0 0 1]\n",
            "\n",
            "--- Task 1: Cohen Kappa Score (Demonstration) ---\n",
            "Training a temporary model for demonstration purposes...\n",
            "[LightGBM] [Info] Number of positive: 3853, number of negative: 3679\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.303994 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 30931\n",
            "[LightGBM] [Info] Number of data points in the train set: 7532, number of used features: 3370\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.511551 -> initscore=0.046211\n",
            "[LightGBM] [Info] Start training from score 0.046211\n",
            "Model trained successfully.\n",
            "Demonstration Cohen Kappa Score on internal validation set: 0.6597\n",
            "Note: This Kappa score is on an internal split of the training data for demonstration.\n",
            "The actual Task 1 Cohen Kappa would be calculated using the predictions on test_1.csv and its true (hidden) labels.\n",
            "\n",
            "--- Task 2: Predictions for test_2.csv ---\n",
            "Predictions for test_2.csv generated.\n",
            "\n",
            "Example predictions for test_2.csv grouped by series:\n",
            "\n",
            "Series series_1:\n",
            "                                              smiles    series  \\\n",
            "0  C#CC1(O)CCC(N2CC(NC(=O)CNc3nn(C)c4ccc(C(F)(F)F...  series_1   \n",
            "1  C#CC1CCC(N2CC(NC(=O)CNc3nn(C)c4ccc(C(F)(F)F)cc...  series_1   \n",
            "2  C=CCOC1CCC(N2CC(NC(=O)CNc3n[nH]c4ccc(C(F)(F)F)...  series_1   \n",
            "3  C=CCOC1CCC(N2CC(NC(=O)CNc3nn(C)c4ccc(C(F)(F)F)...  series_1   \n",
            "4  C=CCOCC1CCC(N2CC(NC(=O)CNc3nn(C)c4ccc(C(F)(F)F...  series_1   \n",
            "\n",
            "   predicted_class_task2  \n",
            "0                      0  \n",
            "1                      0  \n",
            "2                      1  \n",
            "3                      1  \n",
            "4                      1  \n",
            "\n",
            "Series series_2:\n",
            "                                                smiles    series  \\\n",
            "116  CN1C(=O)N(c2cc(Cl)cc(Cl)c2)C(=O)C12CN(Cc1cc(C(...  series_2   \n",
            "117  CNC(=O)c1ccc(-c2ccc(N3C(=O)N(c4cc(OC)ncn4)C4(C...  series_2   \n",
            "118  COCc1nc(-c2ccc(N3C(=O)N(c4cc(=O)[nH]cn4)C4(CCN...  series_2   \n",
            "119  COCc1nc(-c2ccc(N3C(=O)N(c4cc(O)ncn4)C4(CCN(Cc5...  series_2   \n",
            "120  COc1cc(N2C(=O)N(c3ccc(-c4ccc(-c5cc(=O)[nH][nH]...  series_2   \n",
            "\n",
            "     predicted_class_task2  \n",
            "116                      0  \n",
            "117                      0  \n",
            "118                      0  \n",
            "119                      0  \n",
            "120                      0  \n",
            "\n",
            "Series series_3:\n",
            "                                                smiles    series  \\\n",
            "183  CC1CCC(C)N1CCCNc1nnc(-c2ccc(NC(=O)c3ccccc3F)cc...  series_3   \n",
            "184    CCN(CC)CCCCNc1nnc(-c2ccc(NC(=O)c3ccccc3F)cc2)o1  series_3   \n",
            "185     CCN(CC)CCCNc1nnc(-c2ccc(NC(=O)c3ccccc3F)cc2)o1  series_3   \n",
            "186  CCOc1cc(NC(=O)c2ccccc2F)ccc1-c1nnc(NCCCN2CCCCC...  series_3   \n",
            "187  CCc1cc(-c2nnc(NCCCN3CCCCC3)o2)ccc1NC(=O)c1ccccc1F  series_3   \n",
            "\n",
            "     predicted_class_task2  \n",
            "183                      1  \n",
            "184                      0  \n",
            "185                      1  \n",
            "186                      0  \n",
            "187                      1  \n",
            "\n",
            "Series series_4:\n",
            "                                                smiles    series  \\\n",
            "225  CC(=O)NC1CC(C)(C)Oc2nc(-c3ccc(Cl)cc3Cl)c(-c3cc...  series_4   \n",
            "226  CC(O)C(=O)NC1CC(C)(C)Oc2nc(-c3ccc(Cl)cc3Cl)c(-...  series_4   \n",
            "227  CC1(C)CC(NC(=O)C(C)(C)O)c2cc(-c3ccc(Cl)cc3)c(-...  series_4   \n",
            "228  CC1(C)CC(NC(=O)C(C)(O)C(F)(F)F)c2cc(-c3ccc(Cl)...  series_4   \n",
            "229  CC1(C)CC(NC(=O)C(F)(F)CO)c2cc(-c3ccc(Cl)cc3)c(...  series_4   \n",
            "\n",
            "     predicted_class_task2  \n",
            "225                      0  \n",
            "226                      0  \n",
            "227                      1  \n",
            "228                      0  \n",
            "229                      0  \n",
            "\n",
            "Series series_5:\n",
            "                                                smiles    series  \\\n",
            "263  CC#Cc1ccnc(-c2ccc3c(c2)C2(COC(N)=N2)C2(COC2)CO...  series_5   \n",
            "264   CC#Cc1cncc(-c2cc3c(cc2F)OCC2(CC2)C32COC(N)=N2)c1  series_5   \n",
            "265  CC#Cc1cncc(-c2ccc3c(c2)C2(COC(N)=N2)C2(CC2)CO3)c1  series_5   \n",
            "266  CC#Cc1cncc(-c2ccc3c(c2)C2(COC(N)=N2)C2(COC2)C(...  series_5   \n",
            "267  CC#Cc1cncc(-c2ccc3c(c2)C2(COC(N)=N2)C2(COC2)C(...  series_5   \n",
            "\n",
            "     predicted_class_task2  \n",
            "263                      0  \n",
            "264                      0  \n",
            "265                      0  \n",
            "266                      0  \n",
            "267                      0  \n",
            "\n",
            "Series series_6:\n",
            "                                                smiles    series  \\\n",
            "365  CC(C)(C)OC(=O)NCCN1CC2CN(CCNS(=O)(=O)c3ccc(F)c...  series_6   \n",
            "366  CC(C)S(=O)(=O)NCCN1CC2CN(CCCOc3ccc(C#N)cc3)CC(...  series_6   \n",
            "367  CN(CCCN1CC2CN(CCOc3ccc(C#N)cc3F)CC(C1)O2)S(=O)...  series_6   \n",
            "368  CN(CCN1CC2CN(CCCOc3ccc(F)cc3)CC(C1)O2)S(=O)(=O...  series_6   \n",
            "369  CN(CCN1CC2CN(CCCOc3ccc(F)cc3F)CC(C1)O2)S(=O)(=...  series_6   \n",
            "\n",
            "     predicted_class_task2  \n",
            "365                      0  \n",
            "366                      0  \n",
            "367                      0  \n",
            "368                      0  \n",
            "369                      0  \n",
            "\n",
            "--- Task 2: Evaluation Metric (Average Accuracy by Series) ---\n",
            "To calculate the actual Task 2 metric (average accuracy across 6 series):\n",
            "1. Obtain the true labels for test_2.csv.\n",
            "2. For each of the 6 molecular series:\n",
            "   a. Filter predictions and true labels for that series.\n",
            "   b. Calculate accuracy_score(true_labels_series, predicted_labels_series).\n",
            "3. Average these 6 accuracy scores.\n",
            "Demonstration of grouping (actual calculation requires true labels for test_2.csv):\n",
            "\n",
            "--- Task 3: Identify 200 Most Reliable Predictions from test_1.csv ---\n",
            "Identified 200 most reliable predictions for test_1.csv.\n",
            "Top 5 most reliable predictions for test_1.csv:\n",
            "                                                smiles  predicted_class  \\\n",
            "90                            CC(CS)C(=O)N1CCCC1C(=O)O                0   \n",
            "647                  O=C(O)C(=O)Nc1cccc(-c2nn[nH]n2)c1                0   \n",
            "2    C#CC1CCC(C#N)N1C(=O)CNC1(C)CCN(c2cc(C(=O)O)ccn...                0   \n",
            "656                  O=C(O)c1ccc(O)c2ncc(N3CCOCC3)cc12                0   \n",
            "32                    CC(C(=O)O)c1ccc(C(=O)c2ccccc2)s1                0   \n",
            "\n",
            "     probability_class1  confidence  \n",
            "90             0.000023    0.499977  \n",
            "647            0.000028    0.499972  \n",
            "2              0.000072    0.499928  \n",
            "656            0.000075    0.499925  \n",
            "32             0.000105    0.499895  \n",
            "\n",
            "--- Task 3: Accuracy on Most Reliable (Demonstration) ---\n",
            "Demonstration Accuracy on top 503 most reliable predictions (from internal validation set): 0.9662\n",
            "Note: This accuracy is on an internal split of the training data for demonstration.\n",
            "The actual Task 3 Accuracy would be calculated using the top 200 predictions on test_1.csv and its true (hidden) labels.\n",
            "\n",
            "\n",
            "--- Summary of Files to be Generated for Submission (if uncommented) ---\n",
            "1. task1_predictions.csv: Contains 'smiles' and 'predicted_class_task1' for all molecules in test_1.csv.\n",
            "   (The submission file for Task 3 should be the first 200 rows of this file, if sorted by reliability).\n",
            "   Alternatively, a separate file like task3_top_200_predictions.csv can be made.\n",
            "2. task2_predictions.csv: Contains 'smiles', 'series', and 'predicted_class_task2' for all molecules in test_2.csv.\n",
            "\n",
            "To create the submission file for Task 3 (first 200 rows of test_1.csv, ordered by reliability):\n",
            "  submission_task3_df = top_200_reliable[['smiles', 'predicted_class']]\n",
            "  # submission_task3_df.to_csv('submission_task3.csv', index=False)\n",
            "  The 'task1_predictions.csv' file, if it were to be the base for Task 3, would need to be sorted by reliability first, then the top 200 taken.\n",
            "  A common approach for Kaggle-like challenges is to submit a single prediction file for test_set_1, and the platform evaluates Task 1 and Task 3 from it.\n",
            "  For Task 3, it implies the submitted predictions for test_set_1 should be ordered by reliability, most reliable first.\n",
            "  Let's prepare a test_1_submission_ordered.csv for this purpose:\n",
            "  'test_1_submission_ordered_by_reliability.csv' (if uncommented) would be structured for Task 1 and Task 3 evaluation.\n",
            "  Shape of ordered test_1 submission: (750, 2)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}