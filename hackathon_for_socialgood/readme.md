## Hackathon for social Good

## Requirements

### Step 1. BUILD YOUR DATA TEAM.  Your team can have up to 4 participants and must be registered <> as participating in the hackathon.

###  Step 2: Create a compelling analysis or build an application.

Create a compelling analysis of data that helps us understand the “world’s toughest problems” above in new and unique ways. Analysis should be done in a Databricks or Jupyter notebook and use technologies covered in Spark+AI Summit talks (see agenda here).

OR

Build an application which allows end-users to understand data around the “world’s toughest problems” described above. This could allow users to run queries, build visualizations (maps, charts, graphs, etc), read or otherwise explore the data. 

###  Step 3: Record a video screencast (<= 280 seconds) demonstrating the workbook or application, providing commentary answering the following questions:

- Why did you choose this topic?
- Explain your dataset selection
- How does your project help or might help solve these problems?


### Step 4: Submit the video + notebook source (github link) to the challenge.


## Judging criteria

### Quality of Dataset Selection
How have you combined relevant and interesting datasets as part of your analysis or application?

### Originality
Has this been done before, or is this a new and original idea?

### Completeness
Your analysis or application is easy for the end user to understand, and it provides relevant and insightful information. Your submission follows the challenge requirements.

### Application of Relevant technologies
You’re using technologies presented at Spark + AI Summit in an interesting and meaningful way.
Check - https://databricks.com/sparkaisummit/north-america-2020/apache-spark-training
and Delta Lake, MLflow, TensorFlow, SciKit-Learn, Keras, PyTorch, DeepLearning4J, BigDL and deep learning pipelines.

https://colab.research.google.com/notebooks/intro.ipynb