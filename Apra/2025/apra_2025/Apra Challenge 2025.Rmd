---
title: "Apra Data Science Challenge 2025"
output: html_notebook
---

# Load Libraries

```{r}

packages <- c(
  'ggplot2','tidyverse','plotly','leaflet',
  'shiny','shinyWidgets','shinydashboard',
  'xts','forecast','TTR','treemapify',
  'DT','lubridate','RColorBrewer','scales','stopwords',
  'tidytext','stringr','wordcloud','wordcloud2','scales','dplyr','rfm',
  'SnowballC','textmineR','topicmodels','textclean','tm'
)
for (package in packages) { 
  if (!require(package, character.only = T, quietly = T)) {
    install.packages(package)
    library(package, character.only = T)
  }
}
```

# Load data

```{r}
crm <- read_csv("CRM_interacions_table.csv")
gift <- read_csv("gift_transactions_table.csv")
video <- read_csv("video_email_data_table.csv")
constituent <- read_csv("constituent_profiles_table.csv")
```

# Part 1: The Untapped Potential: Understanding Our Donor Landscape

## CRM Data Overview

```{r}
# CRM Interaction Type
g <- crm %>%
        group_by(CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(CRM_INTERACTION_TYPE, Total) %>%
        ggplot(aes(x = reorder(CRM_INTERACTION_TYPE,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="CRM Interaction Type", y = "Count") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))
      
ggplotly(g)
```

### CRM Interaction Over Time

```{r}
crm <- crm %>%
        mutate(Year = lubridate::year(CRM_INTERACTION_DATE),
               Quarter = lubridate::quarter(CRM_INTERACTION_DATE),
               Month = lubridate::month(CRM_INTERACTION_DATE, label = TRUE),
               DOW = lubridate::wday(CRM_INTERACTION_DATE, label=TRUE))
```

### CRM Interaction by Year

```{r}
crm_year <- crm %>%
group_by(Year, CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(Year,CRM_INTERACTION_TYPE, Total)

   g <- ggplot(crm_year, aes(as.factor(Year), Total, group=CRM_INTERACTION_TYPE, colour = CRM_INTERACTION_TYPE)) + 
      geom_line( linewidth=1) + theme_minimal() +
      labs(x = "Year", y = "Total", color="CRM Interaction Type") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### CRM Interaction by Quarter

```{r}
crm %>%
group_by(Quarter, CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(Quarter,CRM_INTERACTION_TYPE, Total) %>% 
      ggplot(aes(as.factor(Quarter), Total, group=CRM_INTERACTION_TYPE, colour = CRM_INTERACTION_TYPE)) + 
      geom_line( linewidth=1) + theme_minimal() +
      labs(x = "Quarter", y = "Total", color="CRM Interaction Type") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))

```

### CRM Interaction by Month

```{r}
crm %>%
group_by(Month, CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(Month,CRM_INTERACTION_TYPE, Total) %>% 
      ggplot(aes(as.factor(Month), Total, group=CRM_INTERACTION_TYPE, colour = CRM_INTERACTION_TYPE)) + 
      geom_line( linewidth=1) + theme_minimal() +
      labs(x = "Month", y = "Total", color="CRM Interaction Type") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
```

### CRM Interaction by Day of Week

```{r}
crm %>%
group_by(DOW, CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(DOW,CRM_INTERACTION_TYPE, Total) %>% 
      ggplot(aes(as.factor(DOW), Total, group=CRM_INTERACTION_TYPE, colour = CRM_INTERACTION_TYPE)) + 
      geom_line( linewidth=1) + theme_minimal() +
      labs(x = "Day of Week", y = "Total", color="CRM Interaction Type") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
```

## Gift Overview

### Gifts by CRM Interaction Type

```{r}
left_join(gift,crm,by='CONSTITUENT_ID') %>%
  group_by(CRM_INTERACTION_TYPE) %>%
  summarise(Total = mean(AMOUNT)) %>%
  select(CRM_INTERACTION_TYPE,Total) %>%
  ggplot(aes(x = reorder(CRM_INTERACTION_TYPE,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="CRM Interaction Type", y = "Donations") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))


```

### Gifts overtime

```{r}
gift <- gift %>%
        mutate(Year = lubridate::year(GIFT_DATE),
               Quarter = lubridate::quarter(GIFT_DATE),
               Month = lubridate::month(GIFT_DATE, label = TRUE),
               DOW = lubridate::wday(GIFT_DATE, label=TRUE))

```
```{r}
    df <- gift %>%
      mutate(Year = lubridate::year(GIFT_DATE),
             Month = lubridate::month(GIFT_DATE, label = TRUE),
             DOW = lubridate::wday(GIFT_DATE, label=TRUE)) %>%
      filter( Year >= as.double(2015), Month %in% c('Jan','Feb'))
```

### Gift by Year

```{r}
g <- gift %>%
group_by(Year) %>%
        summarise(Total = sum(AMOUNT)) %>%
        select(Year, Total) %>% 
        na.omit() %>%
      ggplot(aes(Year, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Year", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 90, hjust = 1))
ggplotly(g)
```

### Gift by Quarter

```{r}
g <- gift %>%
group_by(Quarter) %>%
        summarise(Total = sum(AMOUNT)) %>%
        select(Quarter, Total) %>% 
        na.omit() %>%
      ggplot(aes(Quarter, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Quarter", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### Gift by Month

```{r}
g <- gift %>%
group_by(Month) %>%
        summarise(Total = sum(AMOUNT)) %>%
        select(Month, Total) %>% 
        na.omit() %>%
      ggplot(aes(Month, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Month", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

Gift by Day of Week

```{r}
g <- gift %>%
group_by(DOW) %>%
        summarise(Total = sum(AMOUNT)) %>%
        select(DOW, Total) %>% 
        na.omit() %>%
      ggplot(aes(DOW, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Day of Week", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

## Video Overview

### Video Views over time

```{r}
video <- video %>%
        mutate(Year = lubridate::year(SENT_DATE),
               Quarter = lubridate::quarter(SENT_DATE),
               Month = lubridate::month(SENT_DATE, label = TRUE),
               DOW = lubridate::wday(SENT_DATE, label=TRUE))
```

### Video views by year

```{r}
g <- video %>%
group_by(Year) %>%
        summarise(Total = sum(VIDEO_VIEWS)) %>%
        select(Year, Total) %>% 
        na.omit() %>%
      ggplot(aes(as.factor(Year), Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Year", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### Video Views by Quarter

```{r}
g <- video %>%
group_by(Quarter) %>%
        summarise(Total = sum(VIDEO_VIEWS)) %>%
        select(Quarter, Total) %>% 
        na.omit() %>%
      ggplot(aes(Quarter, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Quarter", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### Video Views by Month

```{r}
g <- video %>%
group_by(Month) %>%
        summarise(Total = sum(VIDEO_VIEWS)) %>%
        select(Month, Total) %>% 
        na.omit() %>%
      ggplot(aes(Month, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Month", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### Video Views by Day of Week

```{r}
g <- video %>%
group_by(DOW) %>%
        summarise(Total = sum(VIDEO_VIEWS)) %>%
        select(DOW, Total) %>% 
        na.omit() %>%
      ggplot(aes(DOW, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Day of the week", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

# Part 2: Donations Portfolio

## Donor RFM Analysis

```{r}
library('readxl')
rfm_segment <- read_excel("rfm_segments_strategy.xlsx")
rfm_df <- gift %>%
  filter(GIFT_DATE >= '2015-01-01') %>%
  select(CONSTITUENT_ID,GIFT_DATE,AMOUNT) %>%
  na.omit()

names(rfm_df)[names(rfm_df) == 'CONSTITUENT_ID'] <- 'customer_id'

#rfm model setup
analysis_date <- lubridate::as_date(today(), tz = "UTC")

report <- rfm_table_order(rfm_df, customer_id,GIFT_DATE,AMOUNT, analysis_date)
#segment
segment_titles <- rfm_segment$`Donor Portfolio`
#numerical thresholds
r_low <-   c(5, 3, 2, 3, 4, 1, 1, 1, 2, 1)
r_high <-   c(5, 5, 4, 4, 5, 2, 2, 3, 3, 1)
f_low <- c(5, 3, 2, 1, 1, 3, 2, 3, 1, 1)
f_high <- c(5, 5, 4, 3, 3, 4, 5, 5, 3, 5)
m_low <-  c(5, 2, 2, 3, 1, 4, 4, 3, 1, 1)
m_high <-  c(5, 5, 4, 5, 5, 5, 5, 5, 4, 5)

divisions<-rfm_segment(report, segment_titles, r_low, r_high, f_low, f_high, m_low, m_high)

#names(divisions)[names(divisions) == 'customer_id'] <- 'CONSTITUENT_ID'

division_count <- divisions %>% count(segment) %>% arrange(desc(n)) %>% rename(Segment = segment, Count = n)
```

```{r}
divisions<-rfm_segment(report, segment_titles)
```


```{r}

```

### RFM Metrics

```{r}
### rfm metrics - monetary
divisions %>%
group_by(segment) %>%
  summarise(Total = mean(amount)) %>%
  select(segment,Total) %>%
  ggplot(aes(x = reorder(segment,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="Segment", y = "Avg. Monetary") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))

```

```{r}
### rfm metrics - frequency
division_count %>%
group_by(Segment) %>%
  summarise(Total = mean(Count)) %>%
  select(Segment,Total) %>%
  ggplot(aes(x = reorder(Segment,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="Segment", y = "Avg. Frequency") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))

```

```{r}
### rfm metrics - recency
divisions %>%
group_by(segment) %>%
  summarise(Total = mean(recency_days)) %>%
  select(segment,Total) %>%
  ggplot(aes(x = reorder(segment,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="Segment", y = "Avg. Recency") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))
```

```{r}
## constituent ouput
### segment
### transaction, recency, monntary
```

### Donor Segmentation

```{r}
`Portfolios` <- c(unique(division_count$Segment))
ggplot(division_count, aes(area = Count, fill = `Portfolios`, label = `Segment`) ) +
  geom_treemap(stat = "identity",
  position = "identity") +
  geom_treemap_text(place = "centre",size = 12)
```

### Donor Lifetime Value

```{r}
# Calculate average donation per customer
avg_donation_per_customer <- gift %>%
  filter((GIFT_DATE >= '2015-01-01') & (GIFT_DATE < analysis_date)) %>%
  group_by(CONSTITUENT_ID) %>%
  summarize(avg_revenue = mean(AMOUNT))

# Calculate average donor lifespan (simplified, using the number of months)
avg_donor_lifespan <- gift %>%
  group_by(CONSTITUENT_ID) %>% 
  summarize(avg_lifespan = as.numeric(difftime(max(GIFT_DATE), min(GIFT_DATE), units = "days"))) %>%
  na.omit()

# Calculate CLV
clv_df <- inner_join(avg_donation_per_customer,avg_donor_lifespan,by='CONSTITUENT_ID') %>%
group_by(CONSTITUENT_ID) %>%
  mutate(CLV_calc = avg_revenue * avg_lifespan) %>%
  select(CONSTITUENT_ID,CLV_calc)


```

```{r}
# Calculate CLV for different groups
avg_donation_per_customer <- divisions %>%
  group_by(CONSTITUENT_ID) %>%
  summarize(avg_revenue = mean(amount))


```


## Part 3: Donation Prediction

### Donor Forecasting

```{r}
# Forecast info

```

```{r}
# generating range of dates 

```

```{r}



```

```{r}

```

```{r}

```

```{r}

```

```{r}


```

```{r}
  g <- autoplot(gift_daily) +   
        scale_y_continuous(labels = scales::comma) + labs(x ="Gift Date", y = "Gift Amount",
                                                          title = "Daily Gift Chart") + 
        theme(plot.title = element_text(hjust=0.5))
      ggplotly(g)
```

```{r}
    gift_weekly <- apply.weekly(gift_xts, mean) 
      g <- autoplot(gift_weekly) +   
        scale_y_continuous(labels = scales::comma) + labs(x ="Gift Date", y = "Gift Amount",
                                                          title = "Weekly Gift Chart") +
        theme(plot.title = element_text(hjust=0.5))
      ggplotly(g)
```

```{r}
      gift_monthly <- apply.monthly(gift_xts, mean)
      g <- autoplot(gift_monthly) +   
        scale_y_continuous(labels = scales::comma) + labs(x ="Gift Date", y = "Gift Amount",
                                                          title = "Monthly Gift Chart") + 
        theme(plot.title = element_text(hjust=0.5))
      ggplotly(g)
```

```{r}

```
```{r}
```


```{r}
```


```{r}
```




```{r}
# --- . Data Preparation for Forecasting ---
print("Aggregating gift data to monthly totals...")
monthly_donations <- gifts_df %>%
  mutate(GIFT_DATE = ymd(GIFT_DATE)) %>%
  # Extract year and month for grouping
  mutate(year_month = floor_date(GIFT_DATE, "month")) %>%
  group_by(year_month) %>%
  summarise(total_donations = sum(AMOUNT, na.rm = TRUE), .groups = 'drop') %>%
  arrange(year_month)


if (nrow(monthly_donations) == 0) {
  stop("No monthly donation data could be aggregated. Check 'GIFT_DATE' and 'AMOUNT' columns.")
}

print(str_glue("Aggregated {nrow(monthly_donations)} monthly donation records."))
print("Sample of monthly donations:")
print(head(monthly_donations))
print(tail(monthly_donations))
```

```{r}
# --- . Create Time Series Object ---
# Determine start year and month for the time series
start_year <- lubridate::year(min(monthly_donations$year_month))
start_month <- lubridate::month(min(monthly_donations$year_month))

# Create a ts object
# Ensure no gaps in the time series if possible, or handle them
# For direct aggregation, gaps won't be explicitly in the data frame if no donations occur
# but the ts object can represent them.
donations_ts <- ts(monthly_donations$total_donations,
                    start = c(start_year, start_month),
                    frequency = 12)

print(str_glue("Created time series object starting from {start_year}-{start_month}."))
print(donations_ts)
```

```{r}
# --- . Validate Seasonality ---
#png("donations_ts_plot.png", width=800, height=500)
plot(donations_ts, main = "Monthly Donations Time Series",
     xlab = "Year", ylab = "Total Donations", col = "steelblue", lwd = 2)
#dev.off()
#print("Time series plot saved as 'donations_ts_plot.png'.")

```

```{r}

# --- Time Series Decomposition (Additive and Multiplicative) ---
# Use additive if seasonal fluctuations are roughly constant over time
# Use multiplicative if seasonal fluctuations increase/decrease with the level of the series
tryCatch({
  decomp_add <- decompose(donations_ts, type = "additive")
  png("donations_decomp_additive.png", width=800, height=600)
  plot(decomp_add)
  dev.off()
  print("Additive decomposition plot saved as 'donations_decomp_additive.png'.")
}, error = function(e) {
  message("Could not perform additive decomposition (e.g., if series is too short): ", e$message)
})

tryCatch({
  decomp_mult <- decompose(donations_ts, type = "multiplicative")
  png("donations_decomp_multiplicative.png", width=800, height=600)
  plot(decomp_mult)
  dev.off()
  print("Multiplicative decomposition plot saved as 'donations_decomp_multiplicative.png'.")
}, error = function(e) {
  message("Could not perform multiplicative decomposition (e.g., if series is too short or has zeros/negatives): ", e$message)
})


```

```{r}
# ---Seasonal Subseries Plots ---
png("donations_seasonal_subseries_plot.png", width=800, height=500)
seasonplot(donations_ts, year.labels = TRUE, year.labels.left = TRUE,
           main = "Seasonal Subseries Plot of Monthly Donations",
           xlab = "Month", ylab = "Total Donations", col = rainbow(length(unique(year(time(donations_ts)))))
)
dev.off()
print("Seasonal subseries plot saved as 'donations_seasonal_subseries_plot.png'.")
```

```{r}
# ---STL Decomposition (Robust Decomposition)
tryCatch({
  stl_decomp <- stl(donations_ts, s.window = "periodic")
  png("donations_stl_decomp_plot.png", width=800, height=600)
  plot(stl_decomp)
  dev.off()
  print("STL decomposition plot saved as 'donations_stl_decomp_plot.png'.")

  # Print summary of STL decomposition (e.g., seasonal, trend, remainder components)
  print("\nSTL Decomposition Summary:")
  print(summary(stl_decomp))

}, error = function(e) {
  message("Could not perform STL decomposition (e.g., if series is too short): ", e$message)
})
```

```{r}
# ---Stationarity Test (Optional, for ARIMA) --
# ADF test for stationarity (null hypothesis: series has a unit root, i.e., non-stationary)
# KPSS test for stationarity (null hypothesis: series is trend-stationary)
print("\nStationarity Tests (for ARIMA suitability):")
adf_result <- adf.test(donations_ts)
print("ADF Test:")
print(adf_result)

kpss_result <- kpss.test(donations_ts)
print("KPSS Test:")
print(kpss_result)
```

```{r}

```

```{r}
# --- 4. Model Training (Automatic ARIMA) ---
print("Training an automatic ARIMA model...")
# auto.arima automatically selects the best ARIMA model
# It handles seasonality by default
arima_model <- auto.arima(donations_ts)
print("ARIMA Model Summary:")
print(summary(arima_model))
```

```{r}
png("arima_residuals_check.png", width=800, height=500)
checkresiduals(arima_model)
dev.off()
print("ARIMA residuals plot saved as 'arima_residuals_check.png'.")
```

```{r}
# ---Using ets for automatic ETS model selection
print("\nFitting ETS Model with ets:")
fit_ets <- ets(donations_ts)
print(summary(fit_ets))
```

```{r}
# --- Check residuals for white noise
png("ets_residuals_check.png", width=800, height=500)
checkresiduals(fit_ets)
dev.off()
print("ETS residuals plot saved as 'ets_residuals_check.png'.")
```

```{r}

```

```{r}
# --- 5. Forecast Future Monthly Donations ---
FORECAST_HORIZON <- 12
print(str_glue("Forecasting for the next {FORECAST_HORIZON} months..."))
forecast_arima <- forecast(arima_model, h = FORECAST_HORIZON)
forecast_ets <- forecast(fit_ets, h = FORECAST_HORIZON)

print("\nARIMA Forecast (next 12 months):")
print(forecast_arima)
print("\nETS Forecast (next 12 months):")
print(forecast_ets)
```

```{r}
# Plot forecasts
png("arima_forecast_plot.png", width=800, height=500)
plot(forecast_arima, main = "ARIMA Forecast of Monthly Donations",
     xlab = "Year", ylab = "Total Donations")
dev.off()
print("ARIMA forecast plot saved as 'arima_forecast_plot.png'.")

png("ets_forecast_plot.png", width=800, height=500)
plot(forecast_ets, main = "ETS Forecast of Monthly Donations",
     xlab = "Year", ylab = "Total Donations")
dev.off()
print("ETS forecast plot saved as 'ets_forecast_plot.png'.")
```

```{r}
print("Forecast Summary:")
print(summary(forecast_arima))

# Extracting forecast values and confidence intervals
forecast_df <- as_data_frame(forecast_arima) %>%
  rename(
    `Forecasted Donation` = `Point Forecast`,
    `Lo 80` = `Lo 80`,
    `Hi 80` = `Hi 80`,
    `Lo 95` = `Lo 95`,
    `Hi 95` = `Hi 95`
  ) %>%
  mutate(
    Month = seq(from = max(monthly_donations$year_month) + months(1),
                by = "month",
                length.out = FORECAST_HORIZON)
  ) %>%
  select(Month, `Forecasted Donation`, `Lo 80`, `Hi 80`, `Lo 95`, `Hi 95`)

print("Detailed Forecast (first 5 rows):")
print(head(forecast_df))
print("Detailed Forecast (last 5 rows):")
print(tail(forecast_df))
```

```{r}
saveRDS(forecast_arima,"forecast_model.rda")
```
```{r}
forecast_model = readRDS("forecast_model.rda")
print(forecast_model)
```

```{r}
# --- Visualization ---
print("Generating forecast plot (forecast_plot.png)...")
png("forecast_plot.png", width = 800, height = 500)
plot(forecast_arima,
     main = "Monthly Donation Forecast",
     xlab = "Year",
     ylab = "Total Donations ($)",
     flty = 1, fcol = "blue")
lines(fitted(arima_model), col = "red")
legend("topleft",
       legend = c("Historical Data", "Fitted Values", "Forecasted Values", "80% CI", "95% CI"),
       col = c("black", "red", "blue", "grey", "lightgrey"),
       lty = c(1,1,1,NA,NA), pch = c(NA,NA,NA,22,22),
       pt.bg = c(NA,NA,NA,"grey","lightgrey"), bty = "n")
dev.off()
print("Forecast plot saved as 'forecast_plot.png'.")

print("--- Forecasting Model Generation Complete ---")
```

### Donor Prediction --\> Next Best Donation

```{r}

```

```{r}
rfm_metrics <- divisions   %>%
  select("customer_id","segment","transaction_count","recency_days","amount" )
colnames(rfm_metrics) <- c('CONSTITUENT_ID', "segment","transaction_count","recency_days","amount")
```

```{r}
reference_date <- ymd('2015-01-01') # Keeping user's specified date
    
    crm_agg <- crm %>%
      group_by(CONSTITUENT_ID) %>%
      summarise(
        total_interactions = n(),
        last_interaction_date = max(CRM_INTERACTION_DATE),
        first_interaction_date = min(CRM_INTERACTION_DATE),
        unique_interaction_types = n_distinct(CRM_INTERACTION_TYPE),
        interaction_span_days = as.numeric(difftime(max(CRM_INTERACTION_DATE), min(CRM_INTERACTION_DATE), units = "days")),
        .groups = 'drop'
      ) %>%
      mutate(
        interaction_span_days = ifelse(is.na(interaction_span_days), 0, interaction_span_days),
        interaction_frequency = total_interactions / (interaction_span_days + 1),
        days_since_last_interaction = as.numeric(difftime(reference_date, last_interaction_date, units = "days"))
      ) %>%
      select("CONSTITUENT_ID","total_interactions","unique_interaction_types")
      

```

```{r}
# combine crm and rfm
crm_rfm <- left_join(rfm_metrics,crm_agg, "CONSTITUENT_ID") %>%
  group_by(CONSTITUENT_ID) %>%
  select(CONSTITUENT_ID,segment,transaction_count,recency_days,total_interactions, unique_interaction_types,amount) %>%
  na.omit()

```

```{r}
#Label Encoder
labelEncoder <-function(x){
  as.numeric(factor(x))-1
}
#normalize data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
```

```{r}

```

```{r}
set.seed(123)
df_cts <- crm_rfm %>%
  select(CONSTITUENT_ID,transaction_count,recency_days,total_interactions,unique_interaction_types)

df_cat <- crm_rfm %>%
  select(CONSTITUENT_ID,segment)

df_amount <- crm_rfm %>%
  select(CONSTITUENT_ID,amount)
```


```{r}
df_cts <- as.data.frame(df_cts)
df_cat <- as.data.frame(lapply(df_cat, labelEncoder))
```


```{r}
df_new <- cbind(df_cts,df_cat,df_amount)
```


```{r}
df_new$CONSTITUENT_ID <- NULL
df_new$CONSTITUENT_ID <- NULL
df_new$CONSTITUENT_ID <- NULL
```


```{r}
```

```{r}
#create train and test data
set.seed(2021)
sample <- sample.split(df_new,SplitRatio = 0.75)
train <- subset(df_new,sample ==TRUE)
test <- subset(df_new, sample==FALSE)
```

```{r}

```

```{r}
#cl <- makePSOCKcluster(4)
#registerDoParallel(cl)
#train_X <- 
#traun_Y <- data.matrix(train[, c('mpg', 'wt', 'drat', 'qsec')])
fit <- glmnet(train[,c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")], train$amount, alpha = 0)

#stopCluster(cl)
```

```{r}
summary(fit)
```

```{r}
cv_model <- cv.glmnet(data.matrix(train[,c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")]), train$amount, alpha = 0)

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
```

```{r}
plot(cv_model) 
```

```{r}
best_model <- glmnet(data.matrix(train[,c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")]), train$amount, alpha = 0, lambda = best_lambda)
coef(best_model)
```

```{r}
y_predicted <- predict(best_model, s = best_lambda, newx = data.matrix(test[,c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")]))
```

```{r}
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
lm_fit <- train(amount ~ .,
                data = train, 
                method = "lm")
stopCluster(cl)
```

```{r}
amount_pred_lm <- predict(lm_fit, test)

# View model RMSE, Rsquared and MAE values 
postResample(pred = amount_pred_lm, obs = test$amount)
```

```{r}
varImp(lm_fit)
```

#### Random forest

```{r}
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
rf_fit <- train(amount ~ .,
                data = train, 
                method = "rf")
stopCluster(cl)
```

```{r}
amount_pred_rf <- predict(rf_fit, test)

# View model RMSE, Rsquared and MAE values 
postResample(pred = amount_pred_rf, obs = test$amount)
```

```{r}
varImp(rf_fit)
```

```{r}
library(xgboost)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
xgbtree_fit <- train(amount ~ .,
                data = train, 
                method = "xgbTree")
stopCluster(cl)
```

```{r}
amount_pred_xgboost <- predict(xgbtree_fit, test)

# View model RMSE, Rsquared and MAE values 
postResample(pred = amount_pred_xgboost, obs = test$amount)
```

```{r}
varImp(xgbtree_fit)
```

```{r}
xgbtree_fit
```

```{r}
saveRDS(xgbtree_fit,"~/Documents/Coding/hackathon-coding-challenges/Apra/2025/apra_2025/model.rda")
```

```{r}
model_load = readRDS("model.rda")
print(model_load)
```

```{r}

columns = c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")

#Create a Empty DataFrame with 0 rows and n columns
df = data.frame(matrix(nrow = 0, ncol = length(columns))) 

# Assign column names
colnames(df) = columns

```

```{r}
df <- rbind(df, c(1,1300,1,1,2))

```

```{r}
```


```{r}
colnames(df) = columns
```

```{r}
final_predictions <- predict(model_load, df)
```
```{r}
final_predictions
```
# KPIS



## DONOR RELATIONSHIP KPIS

Where would your nonprofit be without its donors?

You already know that building and maintaining relationships with donors is a critical aspect of nonprofit success. These donor relationship metrics will help you see how well you’re managing those relationships and give you a jumping-off point for improvement!

11. DONOR RETENTION RATE

Donor retention rate tells you how many donors your organization retains on a year-over-year basis.

To limit donor acquisition costs, you’ll want your donor retention rate to be as high as possible. Ideally, your acquisition and retention rates would improve concurrently.

Tracking your retention rate can reveal important insights about your organization’s performance, including:

How successful various communication channels are.
If your donor recognition efforts are sufficient.
Which donation methods are preferred for returning donors.
If you do have a less-than-ideal donor retention rate, look to your stewardship practices first. What is your acknowledgment process? When do you follow up? How do you continue communicating with your donors? This should be a good starting point for reevaluating your donor retention efforts.

HOW TO CALCULATE THIS KPI

This graphic explains how to calculate donor retention rate, an important fundraising metric.
To calculate this year’s retention rate, you would divide the number of donors who gave last year and this year by the number of donors who gave last year. Then, you would multiply by 100 to yield a percentage.

EXAMPLE OF THIS KPI

Say you had 65 donors last year, and 20 of those donors also contributed this year.

That means you “retained” 20 of your 65 donors. Your donor retention rate is:

20 / 65 = 0.308

0.308 x 100 = 30.8%

This means your donor retention rate is 30.8% this year.

12. LAPSED DONOR RATE / DONOR CHURN RATE

Your lapsed donor rate tells you the percentage of donors who were not retained from one year to the next. This is also referred to as donor churn rate.

Similar to a low donor retention rate, a high number or a high rate of lapsed donors is an indicator that you should investigate your donor retention efforts, like donor recognition and continued engagement campaigns.

HOW TO CALCULATE THIS KPI

This graphic shows how to calculate lapsed donor rate, a critical fundraising KPI.
To find lapsed donors for this year, you first determine who donated last year. All of the donors who did not contribute again this year would be considered lapsed or churned donors. Next, divide the number of lapsed donors by the number of donors who gave last year. Then, multiply by 100 to get a percentage.

EXAMPLE OF THIS KPI

If you determine that 20 of your 65 donors from last year donated again, that means 45 did not. Thus, your number of lapsed or churned donors is 45. Your lapsed donor rate would then be calculated like this:

45 / 65 = 0.692

0.692 x 100 = 69.2%

Thus, your donor churn rate would be 69.2%.

13. DONOR GROWTH RATE

Donor growth rate measures an increase or decrease in your organization’s total number of donors over a given time period.

Donor growth is considered a “domino metric,” meaning it’s often the result of a compounding list of factors. If donor growth is down, it’s probably not your only metric that’s looking less than ideal. Measuring your donor growth ensures that you’re paying attention to your overall performance and allows your nonprofit to address any concerns early and quickly.

Use this metric in conjunction with some of the others on this list to determine exactly why your number of donors isn’t growing.

HOW TO CALCULATE THIS KPI

This graphic shows you how to calculate donor growth rate, another important fundraising metric.
You’ll find your donor growth rate by subtracting the number of donors last year from the number of donors this year. Then, divide the resulting number by the number of donors last year. Next, you’ll take that number and multiply it by 100 to get a percentage.

EXAMPLE OF THIS KPI

Say you had 100 donors last year and 125 donors this year. Here’s how you would calculate your donor growth rate:

125 – 100 = 25

25 / 100 = 0.25

0.25 x 100 = 25%

So, your donor growth rate this year is 25%.

14. DONOR LIFETIME VALUE

Donor lifetime value (DLV) is a way to quantify the overall value a given donor will have for your organization. It’s important to recognize that this number is mainly used to make decisions about where to dedicate fundraising efforts and strategic campaigns. It is not useful as an assessment of a single donor’s lifetime value, but rather as an average lifetime value for a given subset of donors.

HOW TO CALCULATE THIS KPI

This graphic shows you how to calculate donor lifetime value, a valuable fundraising KPI.
You calculate DLV with three numbers you’ll need to find beforehand:

Average length of time as an active donor (This is also known as donor lifetime or donor lifespan.)
Average donation amount
Average frequency of donation
To find the average DLV, you’ll multiply these three averages together (average length of time as an active donor x average donation amount x average frequency of donation).

EXAMPLE OF THIS KPI

Say you wanted to know the differences in DLV between donors acquired by mail and donors acquired online to know which channel to prioritize.

First, you would find the above averages based on your collected donor data for the two groups.

Then, for each group, you would take the average length of time as an active donor and multiply it by the average donation amount, then multiply that by the average donation frequency.

The resulting numbers represent the total donation potential or DLV for the average donor from both groups.





## ONLINE PERFORMANCE
ONLINE GIFT PERCENTAGE

Online gift percentage is a measure of how many of your donations come from online vs. other channels like fundraising events and mail-in donations.

Your online gift percentage, if lower than anticipated or lower than peer organizations’ rates, may indicate you need to step up your digital marketing and/or email campaigns.

You can also use online gift percentage when planning a marketing strategy for the upcoming year/month/etc. For instance, the percentage of donations that come from online vs. direct mail can guide your budgeting process and help you allocate funds to the most useful channels.

HOW TO CALCULATE THIS KPI

This graphic shows you how to calculate online gift percentage, a useful nonprofit fundraising KPI.
Calculate online gift percentage by dividing the number of online gifts by the total number of gifts over a given time period. Then, multiply that number by 100 to obtain a percentage.

EXAMPLE OF THIS KPI

Say you’ve received 600 gifts over a period of six months and want to know what percent of those gifts were made online. You see that 450 gifts were made online.

Thus, your online gift percentage calculation would look like this:

450 / 600 = 0.75

0.75 x 100 = 75%

So, your online gift percentage for that six-month period was 75%.

26. EMAIL OPEN RATE

Email open rate is the percentage of email recipients who actually opened the given campaign, newsletter, or request.

Email open rates are incredibly useful for guiding your email marketing choices. Once you have a baseline open rate, try changing one thing about your emails at a time. Consider altering:

Subject line
Sender name/email address
Time of sending
The open rate results after every change will be invaluable evidence for the success or failure of each change you make, helping you build a strategy supported by the numbers.

HOW TO CALCULATE THIS KPI

This graphic shows you how to calculate email open rate, a useful nonprofit fundraising metric.
To find email open rate, divide the number of email recipients who opened your email by the number of total email recipients. Then, multiply the resulting number by 100 to get a percentage.

EXAMPLE OF THIS KPI

Maybe you send out 800 emails to remind a particular segment of your donors about an upcoming fundraising event. Of the 800 people who receive your email, 300 people open the email.

You would calculate your email open rate like this:

300 / 800 = 0.375

0.375 x 100 = 37.5%

So, your email open rate for your event reminder email was 37.5%.

27. EMAIL CLICK-THROUGH RATE

Email click-through rate describes the percentage of people who click on links in your emails to access other pages, like your website or donation page. Used in combination with email open rates and conversion rates, this metric can help you identify where your marketing is weakest.

If you have a low email click-through rate, try repositioning your calls-to-action (CTAs) to more prominent or clear locations and personalizing your emails as much as possible through smart donor segmentation.

HOW TO CALCULATE THIS KPI

This graphic shows you how to calculate email click-through rate, a critical nonprofit fundraising KPI.
Email click-through rate is obtained by dividing the number of subscribers who click on a link in your email by the total number of emails delivered. Then, multiply the resulting number by 100 to yield a percentage.

EXAMPLE OF THIS KPI

Your nonprofit sends its weekly email newsletter to 500 recipients. Of those 500 recipients, 60 click through to your donation page.

You would calculate your email click-through rate like this:

60 / 500 = 0.12

0.12 x 100 = 12%

Your email click-through rate for this edition of your newsletter was 12%.

28. EMAIL OPT-OUT RATE

Email opt-out rate is a representation of how many of your email subscribers “unsubscribe” from the email stream.

If too many people unsubscribe from an email stream or newsletter, the communication stream gets labeled as spam and begins getting filtered out from your subscribers’ inboxes. Email opt-out rate can help you keep track of opt-outs before it gets to that point, giving you time to reconsider your email approach.

HOW TO CALCULATE THIS KPI

This graphic tells you how to calculate email opt-out rate, an important online engagement fundraising metric.
To find your email opt-out rate, divide the number of unsubscribed by the number of total emails delivered. Then, multiply by 100 to get a percentage.

EXAMPLE OF THIS KPI

Perhaps you want to know the email opt-out rate for your annual email campaign leading up to Giving Tuesday. You see that 5,000 emails have been delivered, and 2,500 people have unsubscribed from your email campaign.

To calculate your email opt-out rate, you would do the following:

2,500 / 5,000 = 0.5

0.5 x 100 = 50%

So, your email opt-out rate for this campaign is 50%.

29. WEBSITE PAGE VIEWS

Website page views refers to the number of times users access pages on your nonprofit’s website. It’s important to note that website page views is not a metric describing how many people accessed a site; it’s merely the number of times the page was loaded/viewed. There is no way to account for repeat viewings, so if a volunteer trying to find information for an event accesses the same page 10 times, that will increase that page’s views by 10.

Website page views are useful especially in combination with other digital metrics like email open rates and click-through rates to try to pinpoint what part of your digital marketing needs improvement. If you have high open rates, high click-through rates, and high page views, but low conversion rates, it’s probably an indicator of a weakness in your website’s content or design.

Try moving your CTAs to more prominent locations, increasing emotional appeals, and clarifying your mission/purpose on your home page.

HOW TO CALCULATE THIS KPI

This graphic shows you how to determine website page views, a useful nonprofit fundrdaising KPI.
There’s no need to do any calculations to figure out website page views. Simply use a tool like Google Analytics to get the number of views.

EXAMPLE OF THIS KPI

You might compare the website page views for your informational page on volunteering and your volunteer registration page to figure out if visitors are acting on the information they’re getting or not.

You use an analytics tool to see that your informational page has gotten 5,000 views in the past month, whereas your registration page has gotten 4,500 views in the last month.

30. LANDING PAGE CONVERSION RATE

Landing page conversion rate measures how many of your page visitors actually complete the goal action on the page, like donating or downloading something.

After you’ve done the hard work of getting donors to your landing page, the last thing you want them to do is click away because a form is too long or confusing. A lower-than-expected landing page conversion rate may indicate room for improvement on your landing page, such as streamlining or shortening the requested fields on your donation form.

HOW TO CALCULATE THIS KPI

This graphic shows you how to calculate landing page conversion rate, a useful nonprofit fundraising KPI.
To find landing page conversion rate, divide the number of page visitors who completed the goal action by the total number of landing page visitors. Then, multiply by 100 to get a percentage.

EXAMPLE OF THIS KPI

Perhaps you see that your donation page has had 10,000 visitors in the last month. But you see that only 3,000 people have completed a donation after landing on your page.

Here’s how you would calculate the landing page conversion rate:

3,000 / 10,000 = 0.3

0.3 x 100 = 30%

So, your landing page conversion rate for your donation page would be 30%.

31. AMPLIFICATION RATE

Amplification rate tells you the ratio of shares per social media post to the number of overall followers. This makes this metric handy for understanding how often your followers are sharing your social media content., thus spreading your content through their own personal networks of family, friends, and coworkers.

HOW TO CALCULATE THIS KPI

This graphic shows you how to calculate amplification rate, a useful nonprofit fundraising metric.
To find amplification rate, divide the number of shares your social media post got by the total number of followers you have on that platform. Then, multiply the resulting number by 100 to yield a percentage.

EXAMPLE OF THIS KPI

Say your nonprofit has 120,000 followers on Twitter, and a recent tweet about an upcoming in-kind donation drive gets shared 90,000 times.

Here’s how you would calculate your amplification rate:

90,000 / 120,000 = 0.75

0.75 x 100 = 75%

Thus, your amplification rate would be 75%.

32. APPLAUSE RATE

Applause rate is the number of approval actions (such as likes) a single post received relative to the number of followers you have on that platform. Understanding your applause rate can help you know which types of posts get the most attention from your audience on each platform you’re using.

HOW TO CALCULATE THIS KPI

This graphic tells you how to calculate applause rate, an important nonprofit fundraising metric.
To find your applause rate, divide the total number of approval actions on a single post (within a set period of time) by the total number of followers you have on that platform. Then, multiply by 100 to get a percentage.

EXAMPLE OF THIS KPI

Say you posted a picture on Facebook of your volunteers hard at work and want to measure its applause rate over the last month. You see that the post has gotten 60 shares over the last month. You also see that you have 400 followers on Facebook.

So, to calculate the applause rate for this particular post, you would do the following:

60 / 400 = 0.15

0.15 x 100 = 15%

Your applause rate for this post is 15%.


## GIVING LEVEL METRICS

### GIFT FREQUENCY
 

Gift frequency tells you the average number of gifts you receive from your donor pool within a set time period (like a year).

HOW TO CALCULATE THIS KPI

This graphic shows you how to calculate gift frequency, a useful fundraising metric.
To figure out your gift frequency, all you’ll need to do is add up the number of times your donors make a gift in a given time period. Then, divide that number by the total number of donors your nonprofit has.

EXAMPLE OF THIS KPI

Say that you’re looking at a time period of one year. You have 500 active donors, and over that year, some donors give multiple times and some only give once. You add up the total of number donations over that year to be 780.

You calculate your gift frequency like this:

780 / 500 = 1.56

Thus, your gift frequency would be 1.56.

### AVERAGE GIFT SIZE

Average gift size is the average donation amount in a given donor group, campaign, or time period. This is a metric best used when tracked on a recurring basis. That way, you can see if your gift size is growing, staying the same, or decreasing.

There are a few ways of going about this. Measure average gift size:

At the same event year-over-year to see your progress.
At all of your events for the year (or, multiple years) to determine which events draw the largest donations.
Over a repeated, fixed time frame (like six months or a year) to track general changes.
Average gift size can be a big help in evaluating the success of your fundraising and major gift efforts.

HOW TO CALCULATE THIS KPI

This graphic shows you how to calculate average gift size, another fundraising KPI.
To calculate average gift size, divide the total amount received by the number of gifts received.

EXAMPLE OF THIS KPI

You want to measure your average gift size for the past six months. You total the number of gifts you’ve received over that time and get 89. Then you add up the dollar amounts of each of those gifts to get $3,000.

So, to calculate the average gift size over the last six month, you do the following:

$3,000 / 89 = $33.71

Thus, the average gift size over the last six months is $33.71.

### AVERAGE GIFT SIZE GROWTH

Average gift size growth measures the percent increase in average gift size year-over-year. This KPI is useful to contextualize donor growth. If donor growth is increasing but average gift size is not, you might want to spend less time focusing on bringing in new donors and more time cultivating the ones you have.

HOW TO CALCULATE THIS KPI

This graphic shows how to calculate average gift size growth, another important nonprofit fundraising metric.
To determine average gift size growth, subtract the average gift size last year from the average gift size this year. Take that number and divide it by the average gift size from last year. Then, multiply by 100 to get a percentage.

In other words:

Avg. gift size growth = ((avg. gift size this year – avg. gift size last year)/avg. gift size last year) x 100

EXAMPLE OF THIS KPI

Your nonprofit’s average gift size last year was $80. This year, your average gift size is $95. To calculate your average gift size growth, you would do the following:

95 – 80 = 15

15 / 80 = 0.188

0.188 x 100 = 18.75%

Thus, your average gift size growth over the last year was 18.75%

## ENGAGEMENT METRICS
### FREQUENCY OF CONTACT WITH DONORS / OUTREACH RATE

Also known as outreach rate, this metric simply tells you how often your team is reaching out to your individual donors over a set period of time.

You can find this value for individual donors, but it’s most useful when averaged across a donor group. For example, to see if the frequency of donor contact influences conversion rates, determine the average contact frequency in the groups that did and didn’t convert and compare them.

Determining a good rhythm for donor contact is often a point of difficulty for nonprofits. Too much contact can become a nuisance and turn donors off, while too little risks losing potential donors. This value can help you establish a baseline from which to work to an optimal contact schedule.

Don’t forget to account for all the different communication channels, like:

Phone calls
Discussions at events
Meetings
Emails

