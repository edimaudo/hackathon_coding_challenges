---
title: "Apra Data Science Challenge 2025"
output: html_notebook
---

# Load Libraries

```{r}

packages <- c(
  'ggplot2','tidyverse','plotly','leaflet',
  'shiny','shinyWidgets','shinydashboard',
  'xts','forecast','TTR','treemapify',
  'DT','lubridate','RColorBrewer','scales','stopwords',
  'tidytext','stringr','wordcloud','wordcloud2','scales','dplyr','rfm',
  'SnowballC','textmineR','topicmodels','textclean','tm'
)
for (package in packages) { 
  if (!require(package, character.only = T, quietly = T)) {
    install.packages(package)
    library(package, character.only = T)
  }
}
```

# Load data

```{r}
crm <- read_csv("CRM_interacions_table.csv")
gift <- read_csv("gift_transactions_table.csv")
video <- read_csv("video_email_data_table.csv")
constituent <- read_csv("constituent_profiles_table.csv")
```

# Part 1: The Untapped Potential: Understanding Our Donor Landscape

## CRM Data Overview

```{r}
# CRM Interaction Type
g <- crm %>%
        group_by(CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(CRM_INTERACTION_TYPE, Total) %>%
        ggplot(aes(x = reorder(CRM_INTERACTION_TYPE,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="CRM Interaction Type", y = "Count") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))
      
ggplotly(g)
```

### CRM Interaction Over Time

```{r}
crm <- crm %>%
        mutate(Year = lubridate::year(CRM_INTERACTION_DATE),
               Quarter = lubridate::quarter(CRM_INTERACTION_DATE),
               Month = lubridate::month(CRM_INTERACTION_DATE, label = TRUE),
               DOW = lubridate::wday(CRM_INTERACTION_DATE, label=TRUE))
```

### CRM Interaction by Year

```{r}
crm_year <- crm %>%
group_by(Year, CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(Year,CRM_INTERACTION_TYPE, Total)

   g <- ggplot(crm_year, aes(as.factor(Year), Total, group=CRM_INTERACTION_TYPE, colour = CRM_INTERACTION_TYPE)) + 
      geom_line( linewidth=1) + theme_minimal() +
      labs(x = "Year", y = "Total", color="CRM Interaction Type") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### CRM Interaction by Quarter

```{r}
crm %>%
group_by(Quarter, CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(Quarter,CRM_INTERACTION_TYPE, Total) %>% 
      ggplot(aes(as.factor(Quarter), Total, group=CRM_INTERACTION_TYPE, colour = CRM_INTERACTION_TYPE)) + 
      geom_line( linewidth=1) + theme_minimal() +
      labs(x = "Quarter", y = "Total", color="CRM Interaction Type") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))

```

### CRM Interaction by Month

```{r}
crm %>%
group_by(Month, CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(Month,CRM_INTERACTION_TYPE, Total) %>% 
      ggplot(aes(as.factor(Month), Total, group=CRM_INTERACTION_TYPE, colour = CRM_INTERACTION_TYPE)) + 
      geom_line( linewidth=1) + theme_minimal() +
      labs(x = "Month", y = "Total", color="CRM Interaction Type") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
```

### CRM Interaction by Day of Week

```{r}
crm %>%
group_by(DOW, CRM_INTERACTION_TYPE) %>%
        summarise(Total = n()) %>%
        select(DOW,CRM_INTERACTION_TYPE, Total) %>% 
      ggplot(aes(as.factor(DOW), Total, group=CRM_INTERACTION_TYPE, colour = CRM_INTERACTION_TYPE)) + 
      geom_line( linewidth=1) + theme_minimal() +
      labs(x = "Day of Week", y = "Total", color="CRM Interaction Type") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
```

## Gift Overview

### Gifts by CRM Interaction Type

```{r}
left_join(gift,crm,by='CONSTITUENT_ID') %>%
  group_by(CRM_INTERACTION_TYPE) %>%
  summarise(Total = mean(AMOUNT)) %>%
  select(CRM_INTERACTION_TYPE,Total) %>%
  ggplot(aes(x = reorder(CRM_INTERACTION_TYPE,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="CRM Interaction Type", y = "Donations") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))


```

### Gifts overtime

```{r}
gift <- gift %>%
        mutate(Year = lubridate::year(GIFT_DATE),
               Quarter = lubridate::quarter(GIFT_DATE),
               Month = lubridate::month(GIFT_DATE, label = TRUE),
               DOW = lubridate::wday(GIFT_DATE, label=TRUE))

```
```{r}
    df <- gift %>%
      mutate(Year = lubridate::year(GIFT_DATE),
             Month = lubridate::month(GIFT_DATE, label = TRUE),
             DOW = lubridate::wday(GIFT_DATE, label=TRUE)) %>%
      filter( Year >= as.double(2015), Month %in% c('Jan','Feb'))
```

### Gift by Year

```{r}
g <- gift %>%
group_by(Year) %>%
        summarise(Total = sum(AMOUNT)) %>%
        select(Year, Total) %>% 
        na.omit() %>%
      ggplot(aes(Year, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Year", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 90, hjust = 1))
ggplotly(g)
```

### Gift by Quarter

```{r}
g <- gift %>%
group_by(Quarter) %>%
        summarise(Total = sum(AMOUNT)) %>%
        select(Quarter, Total) %>% 
        na.omit() %>%
      ggplot(aes(Quarter, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Quarter", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### Gift by Month

```{r}
g <- gift %>%
group_by(Month) %>%
        summarise(Total = sum(AMOUNT)) %>%
        select(Month, Total) %>% 
        na.omit() %>%
      ggplot(aes(Month, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Month", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

Gift by Day of Week

```{r}
g <- gift %>%
group_by(DOW) %>%
        summarise(Total = sum(AMOUNT)) %>%
        select(DOW, Total) %>% 
        na.omit() %>%
      ggplot(aes(DOW, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Day of Week", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

## Video Overview

### Video Views over time

```{r}
video <- video %>%
        mutate(Year = lubridate::year(SENT_DATE),
               Quarter = lubridate::quarter(SENT_DATE),
               Month = lubridate::month(SENT_DATE, label = TRUE),
               DOW = lubridate::wday(SENT_DATE, label=TRUE))
```

### Video views by year

```{r}
g <- video %>%
group_by(Year) %>%
        summarise(Total = sum(VIDEO_VIEWS)) %>%
        select(Year, Total) %>% 
        na.omit() %>%
      ggplot(aes(as.factor(Year), Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Year", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### Video Views by Quarter

```{r}
g <- video %>%
group_by(Quarter) %>%
        summarise(Total = sum(VIDEO_VIEWS)) %>%
        select(Quarter, Total) %>% 
        na.omit() %>%
      ggplot(aes(Quarter, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Quarter", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### Video Views by Month

```{r}
g <- video %>%
group_by(Month) %>%
        summarise(Total = sum(VIDEO_VIEWS)) %>%
        select(Month, Total) %>% 
        na.omit() %>%
      ggplot(aes(Month, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Month", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

### Video Views by Day of Week

```{r}
g <- video %>%
group_by(DOW) %>%
        summarise(Total = sum(VIDEO_VIEWS)) %>%
        select(DOW, Total) %>% 
        na.omit() %>%
      ggplot(aes(DOW, Total)) + 
      geom_bar(stat = "identity",width = 0.5, fill='black') + theme_minimal() +
      labs(x = "Day of the week", y = "Total") + 
      scale_y_continuous(labels = comma) +
      theme(legend.text = element_text(size = 10),
            legend.title = element_text(size = 10),
            axis.title = element_text(size = 10),
            axis.text = element_text(size = 10),
            axis.text.x = element_text(angle = 0, hjust = 1))
ggplotly(g)
```

# Part 2: Donations Portfolio

## Donor RFM Analysis

```{r}
library('readxl')
rfm_segment <- read_excel("rfm_segments_strategy.xlsx")
rfm_df <- gift %>%
  filter(GIFT_DATE >= '2015-01-01') %>%
  select(CONSTITUENT_ID,GIFT_DATE,AMOUNT) %>%
  na.omit()

names(rfm_df)[names(rfm_df) == 'CONSTITUENT_ID'] <- 'customer_id'

#rfm model setup
analysis_date <- lubridate::as_date(today(), tz = "UTC")

report <- rfm_table_order(rfm_df, customer_id,GIFT_DATE,AMOUNT, analysis_date)
#segment
segment_titles <- rfm_segment$`Donor Portfolio`
#numerical thresholds
r_low <-   c(5, 3, 2, 3, 4, 1, 1, 1, 2, 1)
r_high <-   c(5, 5, 4, 4, 5, 2, 2, 3, 3, 1)
f_low <- c(5, 3, 2, 1, 1, 3, 2, 3, 1, 1)
f_high <- c(5, 5, 4, 3, 3, 4, 5, 5, 3, 5)
m_low <-  c(5, 2, 2, 3, 1, 4, 4, 3, 1, 1)
m_high <-  c(5, 5, 4, 5, 5, 5, 5, 5, 4, 5)

divisions<-rfm_segment(report, segment_titles, r_low, r_high, f_low, f_high, m_low, m_high)

#names(divisions)[names(divisions) == 'customer_id'] <- 'CONSTITUENT_ID'

division_count <- divisions %>% count(segment) %>% arrange(desc(n)) %>% rename(Segment = segment, Count = n)
```

```{r}
divisions<-rfm_segment(report, segment_titles)
```


```{r}

```

### RFM Metrics

```{r}
### rfm metrics - monetary
divisions %>%
group_by(segment) %>%
  summarise(Total = mean(amount)) %>%
  select(segment,Total) %>%
  ggplot(aes(x = reorder(segment,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="Segment", y = "Avg. Monetary") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))

```

```{r}
### rfm metrics - frequency
division_count %>%
group_by(Segment) %>%
  summarise(Total = mean(Count)) %>%
  select(Segment,Total) %>%
  ggplot(aes(x = reorder(Segment,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="Segment", y = "Avg. Frequency") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))

```

```{r}
### rfm metrics - recency
divisions %>%
group_by(segment) %>%
  summarise(Total = mean(recency_days)) %>%
  select(segment,Total) %>%
  ggplot(aes(x = reorder(segment,Total) ,y = Total))  +
        geom_bar(stat = "identity",width = 0.5, fill='black')  +
        scale_y_continuous(labels = scales::comma) +
        labs(x ="Segment", y = "Avg. Recency") + coord_flip() +
        theme(legend.text = element_text(size = 12),
              legend.title = element_text(size = 12),
              axis.title = element_text(size = 14),
              axis.text = element_text(size = 12))
```

```{r}
## constituent ouput
### segment
### transaction, recency, monntary
```

### Donor Segmentation

```{r}
`Portfolios` <- c(unique(division_count$Segment))
ggplot(division_count, aes(area = Count, fill = `Portfolios`, label = `Segment`) ) +
  geom_treemap(stat = "identity",
  position = "identity") +
  geom_treemap_text(place = "centre",size = 12)
```

### Donor Lifetime Value

```{r}
# Calculate average donation per customer
avg_donation_per_customer <- gift %>%
  filter((GIFT_DATE >= '2015-01-01') & (GIFT_DATE < analysis_date)) %>%
  group_by(CONSTITUENT_ID) %>%
  summarize(avg_revenue = mean(AMOUNT))

# Calculate average donor lifespan (simplified, using the number of months)
avg_donor_lifespan <- gift %>%
  group_by(CONSTITUENT_ID) %>% 
  summarize(avg_lifespan = as.numeric(difftime(max(GIFT_DATE), min(GIFT_DATE), units = "days"))) %>%
  na.omit()

# Calculate CLV
clv_df <- inner_join(avg_donation_per_customer,avg_donor_lifespan,by='CONSTITUENT_ID') %>%
group_by(CONSTITUENT_ID) %>%
  mutate(CLV_calc = avg_revenue * avg_lifespan) %>%
  select(CONSTITUENT_ID,CLV_calc)


```

```{r}
# Calculate CLV for different groups
avg_donation_per_customer <- divisions %>%
  group_by(CONSTITUENT_ID) %>%
  summarize(avg_revenue = mean(amount))


```


## Part 3: Donation Prediction

### Donor Forecasting

```{r}
# Forecast info

```

```{r}
# generating range of dates 

```

```{r}



```

```{r}

```

```{r}

```

```{r}

```

```{r}


```

```{r}
  g <- autoplot(gift_daily) +   
        scale_y_continuous(labels = scales::comma) + labs(x ="Gift Date", y = "Gift Amount",
                                                          title = "Daily Gift Chart") + 
        theme(plot.title = element_text(hjust=0.5))
      ggplotly(g)
```

```{r}
    gift_weekly <- apply.weekly(gift_xts, mean) 
      g <- autoplot(gift_weekly) +   
        scale_y_continuous(labels = scales::comma) + labs(x ="Gift Date", y = "Gift Amount",
                                                          title = "Weekly Gift Chart") +
        theme(plot.title = element_text(hjust=0.5))
      ggplotly(g)
```

```{r}
      gift_monthly <- apply.monthly(gift_xts, mean)
      g <- autoplot(gift_monthly) +   
        scale_y_continuous(labels = scales::comma) + labs(x ="Gift Date", y = "Gift Amount",
                                                          title = "Monthly Gift Chart") + 
        theme(plot.title = element_text(hjust=0.5))
      ggplotly(g)
```

```{r}

```
```{r}
```


```{r}
```


```{r}
```




```{r}
# --- . Data Preparation for Forecasting ---
print("Aggregating gift data to monthly totals...")
monthly_donations <- gifts_df %>%
  mutate(GIFT_DATE = ymd(GIFT_DATE)) %>%
  # Extract year and month for grouping
  mutate(year_month = floor_date(GIFT_DATE, "month")) %>%
  group_by(year_month) %>%
  summarise(total_donations = sum(AMOUNT, na.rm = TRUE), .groups = 'drop') %>%
  arrange(year_month)


if (nrow(monthly_donations) == 0) {
  stop("No monthly donation data could be aggregated. Check 'GIFT_DATE' and 'AMOUNT' columns.")
}

print(str_glue("Aggregated {nrow(monthly_donations)} monthly donation records."))
print("Sample of monthly donations:")
print(head(monthly_donations))
print(tail(monthly_donations))
```

```{r}
# --- . Create Time Series Object ---
# Determine start year and month for the time series
start_year <- lubridate::year(min(monthly_donations$year_month))
start_month <- lubridate::month(min(monthly_donations$year_month))

# Create a ts object
# Ensure no gaps in the time series if possible, or handle them
# For direct aggregation, gaps won't be explicitly in the data frame if no donations occur
# but the ts object can represent them.
donations_ts <- ts(monthly_donations$total_donations,
                    start = c(start_year, start_month),
                    frequency = 12)

print(str_glue("Created time series object starting from {start_year}-{start_month}."))
print(donations_ts)
```

```{r}
# --- . Validate Seasonality ---
#png("donations_ts_plot.png", width=800, height=500)
plot(donations_ts, main = "Monthly Donations Time Series",
     xlab = "Year", ylab = "Total Donations", col = "steelblue", lwd = 2)
#dev.off()
#print("Time series plot saved as 'donations_ts_plot.png'.")

```

```{r}

# --- Time Series Decomposition (Additive and Multiplicative) ---
# Use additive if seasonal fluctuations are roughly constant over time
# Use multiplicative if seasonal fluctuations increase/decrease with the level of the series
tryCatch({
  decomp_add <- decompose(donations_ts, type = "additive")
  png("donations_decomp_additive.png", width=800, height=600)
  plot(decomp_add)
  dev.off()
  print("Additive decomposition plot saved as 'donations_decomp_additive.png'.")
}, error = function(e) {
  message("Could not perform additive decomposition (e.g., if series is too short): ", e$message)
})

tryCatch({
  decomp_mult <- decompose(donations_ts, type = "multiplicative")
  png("donations_decomp_multiplicative.png", width=800, height=600)
  plot(decomp_mult)
  dev.off()
  print("Multiplicative decomposition plot saved as 'donations_decomp_multiplicative.png'.")
}, error = function(e) {
  message("Could not perform multiplicative decomposition (e.g., if series is too short or has zeros/negatives): ", e$message)
})


```

```{r}
# ---Seasonal Subseries Plots ---
png("donations_seasonal_subseries_plot.png", width=800, height=500)
seasonplot(donations_ts, year.labels = TRUE, year.labels.left = TRUE,
           main = "Seasonal Subseries Plot of Monthly Donations",
           xlab = "Month", ylab = "Total Donations", col = rainbow(length(unique(year(time(donations_ts)))))
)
dev.off()
print("Seasonal subseries plot saved as 'donations_seasonal_subseries_plot.png'.")
```

```{r}
# ---STL Decomposition (Robust Decomposition)
tryCatch({
  stl_decomp <- stl(donations_ts, s.window = "periodic")
  png("donations_stl_decomp_plot.png", width=800, height=600)
  plot(stl_decomp)
  dev.off()
  print("STL decomposition plot saved as 'donations_stl_decomp_plot.png'.")

  # Print summary of STL decomposition (e.g., seasonal, trend, remainder components)
  print("\nSTL Decomposition Summary:")
  print(summary(stl_decomp))

}, error = function(e) {
  message("Could not perform STL decomposition (e.g., if series is too short): ", e$message)
})
```

```{r}
# ---Stationarity Test (Optional, for ARIMA) --
# ADF test for stationarity (null hypothesis: series has a unit root, i.e., non-stationary)
# KPSS test for stationarity (null hypothesis: series is trend-stationary)
print("\nStationarity Tests (for ARIMA suitability):")
adf_result <- adf.test(donations_ts)
print("ADF Test:")
print(adf_result)

kpss_result <- kpss.test(donations_ts)
print("KPSS Test:")
print(kpss_result)
```

```{r}

```

```{r}
# --- 4. Model Training (Automatic ARIMA) ---
print("Training an automatic ARIMA model...")
# auto.arima automatically selects the best ARIMA model
# It handles seasonality by default
arima_model <- auto.arima(donations_ts)
print("ARIMA Model Summary:")
print(summary(arima_model))
```

```{r}
png("arima_residuals_check.png", width=800, height=500)
checkresiduals(arima_model)
dev.off()
print("ARIMA residuals plot saved as 'arima_residuals_check.png'.")
```

```{r}
# ---Using ets for automatic ETS model selection
print("\nFitting ETS Model with ets:")
fit_ets <- ets(donations_ts)
print(summary(fit_ets))
```

```{r}
# --- Check residuals for white noise
png("ets_residuals_check.png", width=800, height=500)
checkresiduals(fit_ets)
dev.off()
print("ETS residuals plot saved as 'ets_residuals_check.png'.")
```

```{r}

```

```{r}
# --- 5. Forecast Future Monthly Donations ---
FORECAST_HORIZON <- 12
print(str_glue("Forecasting for the next {FORECAST_HORIZON} months..."))
forecast_arima <- forecast(arima_model, h = FORECAST_HORIZON)
forecast_ets <- forecast(fit_ets, h = FORECAST_HORIZON)

print("\nARIMA Forecast (next 12 months):")
print(forecast_arima)
print("\nETS Forecast (next 12 months):")
print(forecast_ets)
```

```{r}
# Plot forecasts
png("arima_forecast_plot.png", width=800, height=500)
plot(forecast_arima, main = "ARIMA Forecast of Monthly Donations",
     xlab = "Year", ylab = "Total Donations")
dev.off()
print("ARIMA forecast plot saved as 'arima_forecast_plot.png'.")

png("ets_forecast_plot.png", width=800, height=500)
plot(forecast_ets, main = "ETS Forecast of Monthly Donations",
     xlab = "Year", ylab = "Total Donations")
dev.off()
print("ETS forecast plot saved as 'ets_forecast_plot.png'.")
```

```{r}
print("Forecast Summary:")
print(summary(forecast_arima))

# Extracting forecast values and confidence intervals
forecast_df <- as_data_frame(forecast_arima) %>%
  rename(
    `Forecasted Donation` = `Point Forecast`,
    `Lo 80` = `Lo 80`,
    `Hi 80` = `Hi 80`,
    `Lo 95` = `Lo 95`,
    `Hi 95` = `Hi 95`
  ) %>%
  mutate(
    Month = seq(from = max(monthly_donations$year_month) + months(1),
                by = "month",
                length.out = FORECAST_HORIZON)
  ) %>%
  select(Month, `Forecasted Donation`, `Lo 80`, `Hi 80`, `Lo 95`, `Hi 95`)

print("Detailed Forecast (first 5 rows):")
print(head(forecast_df))
print("Detailed Forecast (last 5 rows):")
print(tail(forecast_df))
```

```{r}
saveRDS(forecast_arima,"forecast_model.rda")
```
```{r}
forecast_model = readRDS("forecast_model.rda")
print(forecast_model)
```

```{r}
# --- Visualization ---
print("Generating forecast plot (forecast_plot.png)...")
png("forecast_plot.png", width = 800, height = 500)
plot(forecast_arima,
     main = "Monthly Donation Forecast",
     xlab = "Year",
     ylab = "Total Donations ($)",
     flty = 1, fcol = "blue")
lines(fitted(arima_model), col = "red")
legend("topleft",
       legend = c("Historical Data", "Fitted Values", "Forecasted Values", "80% CI", "95% CI"),
       col = c("black", "red", "blue", "grey", "lightgrey"),
       lty = c(1,1,1,NA,NA), pch = c(NA,NA,NA,22,22),
       pt.bg = c(NA,NA,NA,"grey","lightgrey"), bty = "n")
dev.off()
print("Forecast plot saved as 'forecast_plot.png'.")

print("--- Forecasting Model Generation Complete ---")
```

### Donor Prediction --\> Next Best Donation

```{r}

```

```{r}
rfm_metrics <- divisions   %>%
  select("customer_id","segment","transaction_count","recency_days","amount" )
colnames(rfm_metrics) <- c('CONSTITUENT_ID', "segment","transaction_count","recency_days","amount")
```

```{r}
reference_date <- ymd('2015-01-01') # Keeping user's specified date
    
    crm_agg <- crm %>%
      group_by(CONSTITUENT_ID) %>%
      summarise(
        total_interactions = n(),
        last_interaction_date = max(CRM_INTERACTION_DATE),
        first_interaction_date = min(CRM_INTERACTION_DATE),
        unique_interaction_types = n_distinct(CRM_INTERACTION_TYPE),
        interaction_span_days = as.numeric(difftime(max(CRM_INTERACTION_DATE), min(CRM_INTERACTION_DATE), units = "days")),
        .groups = 'drop'
      ) %>%
      mutate(
        interaction_span_days = ifelse(is.na(interaction_span_days), 0, interaction_span_days),
        interaction_frequency = total_interactions / (interaction_span_days + 1),
        days_since_last_interaction = as.numeric(difftime(reference_date, last_interaction_date, units = "days"))
      ) %>%
      select("CONSTITUENT_ID","total_interactions","unique_interaction_types")
      

```

```{r}
# combine crm and rfm
crm_rfm <- left_join(rfm_metrics,crm_agg, "CONSTITUENT_ID") %>%
  group_by(CONSTITUENT_ID) %>%
  select(CONSTITUENT_ID,segment,transaction_count,recency_days,total_interactions, unique_interaction_types,amount) %>%
  na.omit()

```

```{r}
#Label Encoder
labelEncoder <-function(x){
  as.numeric(factor(x))-1
}
#normalize data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
```

```{r}

```

```{r}
set.seed(123)
df_cts <- crm_rfm %>%
  select(CONSTITUENT_ID,transaction_count,recency_days,total_interactions,unique_interaction_types)

df_cat <- crm_rfm %>%
  select(CONSTITUENT_ID,segment)

df_amount <- crm_rfm %>%
  select(CONSTITUENT_ID,amount)
```


```{r}
df_cts <- as.data.frame(df_cts)
df_cat <- as.data.frame(lapply(df_cat, labelEncoder))
```


```{r}
df_new <- cbind(df_cts,df_cat,df_amount)
```


```{r}
df_new$CONSTITUENT_ID <- NULL
df_new$CONSTITUENT_ID <- NULL
df_new$CONSTITUENT_ID <- NULL
```


```{r}
```

```{r}
#create train and test data
set.seed(2021)
sample <- sample.split(df_new,SplitRatio = 0.75)
train <- subset(df_new,sample ==TRUE)
test <- subset(df_new, sample==FALSE)
```

```{r}

```

```{r}
#cl <- makePSOCKcluster(4)
#registerDoParallel(cl)
#train_X <- 
#traun_Y <- data.matrix(train[, c('mpg', 'wt', 'drat', 'qsec')])
fit <- glmnet(train[,c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")], train$amount, alpha = 0)

#stopCluster(cl)
```

```{r}
summary(fit)
```

```{r}
cv_model <- cv.glmnet(data.matrix(train[,c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")]), train$amount, alpha = 0)

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
```

```{r}
plot(cv_model) 
```

```{r}
best_model <- glmnet(data.matrix(train[,c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")]), train$amount, alpha = 0, lambda = best_lambda)
coef(best_model)
```

```{r}
y_predicted <- predict(best_model, s = best_lambda, newx = data.matrix(test[,c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")]))
```

```{r}
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
lm_fit <- train(amount ~ .,
                data = train, 
                method = "lm")
stopCluster(cl)
```

```{r}
amount_pred_lm <- predict(lm_fit, test)

# View model RMSE, Rsquared and MAE values 
postResample(pred = amount_pred_lm, obs = test$amount)
```

```{r}
varImp(lm_fit)
```

#### Random forest

```{r}
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
rf_fit <- train(amount ~ .,
                data = train, 
                method = "rf")
stopCluster(cl)
```

```{r}
amount_pred_rf <- predict(rf_fit, test)

# View model RMSE, Rsquared and MAE values 
postResample(pred = amount_pred_rf, obs = test$amount)
```

```{r}
varImp(rf_fit)
```

```{r}
library(xgboost)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
xgbtree_fit <- train(amount ~ .,
                data = train, 
                method = "xgbTree")
stopCluster(cl)
```

```{r}
amount_pred_xgboost <- predict(xgbtree_fit, test)

# View model RMSE, Rsquared and MAE values 
postResample(pred = amount_pred_xgboost, obs = test$amount)
```

```{r}
varImp(xgbtree_fit)
```

```{r}
xgbtree_fit
```

```{r}
saveRDS(xgbtree_fit,"~/Documents/Coding/hackathon-coding-challenges/Apra/2025/apra_2025/model.rda")
```

```{r}
model_load = readRDS("model.rda")
print(model_load)
```

```{r}

columns = c("transaction_count","recency_days","total_interactions","unique_interaction_types","segment")

#Create a Empty DataFrame with 0 rows and n columns
df = data.frame(matrix(nrow = 0, ncol = length(columns))) 

# Assign column names
colnames(df) = columns

```

```{r}
df <- rbind(df, c(1,1300,1,1,2))

```

```{r}
```


```{r}
colnames(df) = columns
```

```{r}
final_predictions <- predict(model_load, df)
```
```{r}
final_predictions
```
```{r}
# install.packages(c("dplyr","tidyr","ggplot2","ggalluvial","plotly"))
# install.packages(c("dplyr","ggplot2","ggforce","plotly"))
library(dplyr)
library(ggplot2)
library(ggforce)
library(plotly)

# stages (must match column names in video)
stages <- c(
  "CLICKS",
  "STARTED_VIDEO",
  "WATCHED_VIDEO_25_PERCENT",
  "WATCHED_VIDEO_50_PERCENT",
  "WATCHED_VIDEO_75_PERCENT",
  "FINISHED_VIDEO"
)

# defensive checks
missing_cols <- setdiff(stages, names(video))
if (length(missing_cols) > 0) stop("Missing columns in 'video': ", paste(missing_cols, collapse = ", "))

# compute aggregated totals for each stage (works whether columns are 0/1 flags or counts)
totals_df <- tibble(
  stage = stages,
  x = seq_along(stages),
  total = sapply(stages, function(cn) {
    # If column is length-1 (already aggregated count), use it; otherwise sum values
    col <- video[[cn]]
    if (length(col) == 1 && is.numeric(col)) {
      as.numeric(col)  # single aggregate value
    } else {
      sum(as.numeric(col), na.rm = TRUE)
    }
  })
)

# Build bezier link data (one link per adjacent pair). We'll draw a 4-point curve for each pair
link_list <- list()
for (i in 1:(nrow(totals_df)-1)) {
  x1 <- totals_df$x[i]
  x2 <- totals_df$x[i+1]
  y1 <- totals_df$total[i]
  y2 <- totals_df$total[i+1]
  # Use the center y positions for curve endpoints; set control x offsets to smooth the curve
  link_df <- tibble(
    x = c(x1, x1 + 0.3, x2 - 0.3, x2),
    y = c(y1, (y1 + y2)/2, (y1 + y2)/2, y2),
    group = paste0("link", i),
    value = (y1 + y2)/2,         # thickness indicator: average of two stages
    from = totals_df$stage[i],
    to   = totals_df$stage[i+1]
  )
  link_list[[i]] <- link_df
}
links_df <- bind_rows(link_list)

# Prepare labels/hover text
totals_df <- totals_df %>%
  mutate(label = paste0(stage, "\nCount: ", total))

links_df <- links_df %>%
  mutate(hover = paste0("From: ", from, "<br>To: ", to, "<br>Avg flow: ", round(value, 1)))

# Plot:
p <- ggplot() +
  # vertical bars for each stage (centered at x)
  geom_col(data = totals_df, aes(x = x, y = total, text = label),
           width = 0.35, fill = "#2c7fb8", alpha = 0.85) +
  # smoothed flows (drawn as bezier curves) - size mapped to value (scaled)
  geom_bezier(data = links_df,
              aes(x = x, y = y, group = group, size = value, text = hover),
              alpha = 0.6, color = "#f768a1", show.legend = FALSE) +
  # stage labels on x axis
  scale_x_continuous(breaks = totals_df$x, labels = totals_df$stage, expand = c(0.05, 0.05)) +
  scale_size_continuous(range = c(0.5, 8)) +     # adjust thickness mapping
  labs(title = "Aggregated Snakey Chart (ggplotly)",
       subtitle = "Bars = stage totals; curves = aggregated flow width (average of adjacent stages)",
       x = NULL, y = "Total") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 25, hjust = 1),
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank())

# Convert to interactive plotly using our custom tooltips (text)
p_interactive <- ggplotly(p, tooltip = "text") %>%
  layout(legend = list(orientation = "h"))

# Print
p_interactive



```

```{r}
# install.packages(c("dplyr","ggplot2","ggforce","plotly"))
library(dplyr)
library(ggplot2)
library(ggforce)
library(plotly)

stages <- c(
  "CLICKS",
  "STARTED_VIDEO",
  "WATCHED_VIDEO_25_PERCENT",
  "WATCHED_VIDEO_50_PERCENT",
  "WATCHED_VIDEO_75_PERCENT",
  "FINISHED_VIDEO"
)

# Defensive: ensure all columns exist and are numeric
missing_cols <- setdiff(stages, names(video))
if (length(missing_cols) > 0) stop("Missing columns: ", paste(missing_cols, collapse=", "))
video <- video %>% mutate(across(all_of(stages), ~as.integer(.)))

# Stage totals
totals_df <- tibble(
  stage = stages,
  x = seq_along(stages),
  total = sapply(stages, function(s) sum(video[[s]], na.rm = TRUE))
)

# Compute true link (transition) values
links_df <- purrr::map2_dfr(
  stages[-length(stages)], stages[-1],
  \(from, to) {
    tibble(
      from = from,
      to = to,
      source_x = match(from, stages),
      target_x = match(to, stages),
      from_total = sum(video[[from]], na.rm = TRUE),
      to_total = sum(video[[to]], na.rm = TRUE),
      value = sum(video[[from]] == 1 & video[[to]] == 1, na.rm = TRUE)
    )
  }
)

# Normalize y positions for layout
max_total <- max(totals_df$total)
totals_df <- totals_df %>% mutate(y = total / max_total)
links_df <- links_df %>%
  mutate(
    y_from = totals_df$y[source_x],
    y_to = totals_df$y[target_x]
  )

# Prepare Bezier curve data
link_paths <- links_df %>%
  mutate(
    group = paste0(from, "_", to)
  ) %>%
  rowwise() %>%
  do({
    tibble(
      x = c(.$source_x, .$source_x + 0.3, .$target_x - 0.3, .$target_x),
      y = c(.$y_from, (.$y_from + .$y_to)/2, (.$y_from + .$y_to)/2, .$y_to),
      group = .$group,
      value = .$value,
      hover = paste0("From: ", .$from,
                     "<br>To: ", .$to,
                     "<br>Users continuing: ", .$value)
    )
  }) %>%
  ungroup()

# Plot
p <- ggplot() +
  # Flows (curved connectors)
  geom_bezier(
    data = link_paths,
    aes(x = x, y = y, group = group, size = value, text = hover),
    color = "#2c7fb8", alpha = 0.7, show.legend = FALSE
  ) +
  # Stage totals as vertical bars
  geom_col(
    data = totals_df,
    aes(x = x, y = y, text = paste0(stage, "<br>Total: ", total)),
    fill = "#f768a1", width = 0.3, alpha = 0.8
  ) +
  scale_x_continuous(
    breaks = totals_df$x,
    labels = totals_df$stage,
    expand = c(0.05, 0.05)
  ) +
  scale_size_continuous(range = c(1, 10)) +
  labs(
    title = "Snakey Chart: Video Funnel Flow",
    subtitle = "Flow thickness represents users continuing to the next stage",
    x = NULL,
    y = "Normalized Stage Total"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 25, hjust = 1))

# Interactive ggplotly
p_interactive <- ggplotly(p, tooltip = "text")
p_interactive
```


```{r}
# install.packages(c("ggplot2", "ggforce", "plotly", "dplyr", "tidyr", "purrr"))
library(ggplot2)
library(ggforce)
library(plotly)
library(dplyr)
library(tidyr)
library(purrr)

# Define your funnel stages
stages <- c(
  "CLICKS",
  "STARTED_VIDEO",
  "WATCHED_VIDEO_25_PERCENT",
  "WATCHED_VIDEO_50_PERCENT",
  "WATCHED_VIDEO_75_PERCENT",
  "FINISHED_VIDEO"
)

# Ensure numeric binary
video <- video %>%
  mutate(across(all_of(stages), ~as.integer(.)))

# ---- 1. Compute link (transition) counts ----
links_df <- map2_dfr(
  stages[-length(stages)], stages[-1],
  \(from, to) {
    tibble(
      from = from,
      to = to,
      value = sum(video[[from]] == 1 & video[[to]] == 1, na.rm = TRUE)
    )
  }
)

# ---- 2. Compute totals for each stage ----
stage_totals <- tibble(
  stage = stages,
  total = sapply(stages, \(s) sum(video[[s]], na.rm = TRUE)),
  x = seq_along(stages)
)

# ---- 3. Prepare Bezier paths ----
links_df <- links_df %>%
  mutate(
    x_from = match(from, stages),
    x_to = match(to, stages),
    y_from = stage_totals$total[x_from] / max(stage_totals$total),
    y_to = stage_totals$total[x_to] / max(stage_totals$total)
  )

# Create smooth curves between stages
bezier_paths <- links_df %>%
  rowwise() %>%
  mutate(group = paste(from, to, sep = "_")) %>%
  do({
    tibble(
      x = c(.$x_from, .$x_from + 0.3, .$x_to - 0.3, .$x_to),
      y = c(.$y_from, (.$y_from + .$y_to)/2, (.$y_from + .$y_to)/2, .$y_to),
      group = .$group,
      value = .$value,
      hover = paste0(
        .$from, " → ", .$to, "<br>",
        "Users continuing: ", .$value
      )
    )
  }) %>%
  ungroup()

# ---- 4. Build ggplot ----
p <- ggplot() +
  # Flow ribbons (snake lines)
  geom_bezier(
    data = bezier_paths,
    aes(
      x = x, y = y, group = group, size = value, text = hover,
      color = group
    ),
    alpha = 0.7, show.legend = FALSE
  ) +
  # Stage totals as bars
  geom_col(
    data = stage_totals,
    aes(x = x, y = total / max(total), text = paste(stage, ":", total)),
    fill = "#f768a1", width = 0.3, alpha = 0.8
  ) +
  scale_x_continuous(
    breaks = stage_totals$x,
    labels = stage_totals$stage,
    expand = c(0.05, 0.05)
  ) +
  scale_size_continuous(range = c(1, 12)) +
  theme_minimal(base_size = 12) +
  labs(
    title = "Snakey Chart: Video Funnel Flow",
    subtitle = "Interactive ggplotly Sankey-style visualization",
    x = NULL, y = "Relative Stage Size"
  ) +
  theme(
    axis.text.x = element_text(angle = 25, hjust = 1),
    panel.grid = element_blank()
  )

# ---- 5. Make it interactive ----
ggplotly(p, tooltip = "text")

```
```{r}
# install.packages(c("plotly","dplyr","purrr"))
library(plotly)
library(dplyr)
library(purrr)

# Your ordered funnel stages (must match columns in video)
stages <- c(
  "CLICKS",
  "STARTED_VIDEO",
  "WATCHED_VIDEO_25_PERCENT",
  "WATCHED_VIDEO_50_PERCENT",
  "WATCHED_VIDEO_75_PERCENT",
  "FINISHED_VIDEO"
)

# Defensive checks
missing_cols <- setdiff(stages, names(video))
if (length(missing_cols) > 0) stop("Missing columns in 'video': ", paste(missing_cols, collapse = ", "))

# Ensure binary integer columns
video <- video %>% mutate(across(all_of(stages), ~ as.integer(.)))

# Build links: transitions between adjacent stages
links <- map2_dfr(stages[-length(stages)], stages[-1], function(from, to) {
  tibble(
    source_label = from,
    target_label = to,
    value = sum(video[[from]] == 1 & video[[to]] == 1, na.rm = TRUE)
  )
})

# Nodes list (unique stage labels)
nodes <- data.frame(name = stages, stringsAsFactors = FALSE)

# Map labels to 0-based indices for Plotly
links_plotly <- links %>%
  mutate(
    source = match(source_label, nodes$name) - 1,
    target = match(target_label, nodes$name) - 1
  )

# Optional: colors for nodes (same length as stages)
node_colors <- c("#4C78A8", "#F58518", "#E45756", "#72B7B2", "#54A24B", "#B279A2")

# Build and show sankey
fig <- plot_ly(
  type = "sankey",
  arrangement = "snap",
  node = list(
    label = nodes$name,
    color = node_colors,
    pad = 15,
    thickness = 20
  ),
  link = list(
    source = links_plotly$source,
    target = links_plotly$target,
    value = links_plotly$value,
    label = paste0(links_plotly$source_label, " → ", links_plotly$target_label, ": ", links_plotly$value)
  )
)

fig <- fig %>%
  layout(
    title = "Video Funnel Sankey (transition counts between adjacent stages)",
    font = list(size = 12)
  )

fig

```

